{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Physics Based Animation Toolkit","text":""},{"location":"#overview","title":"Overview","text":"<p>We recommend exploring the official CMake documentation to beginner CMake users, if they wish to build this project from source.</p> <p>The Physics Based Animation Toolkit (PBAT) is a (mostly templated) cross-platform C++20 library of algorithms and data structures commonly used in computer graphics research on physically-based simulation in dimensions <code>1,2,3</code>. For most use cases, we recommend using our library via its Python interface, enabling seamless integration into Python's ecosystem of powerful scientific computing packages.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Finite Element Method (FEM) meshes and operators</li> <li>Dimensions <code>1,2,3</code></li> <li>Lagrange shape functions of order <code>1,2,3</code></li> <li>Line, triangle, quadrilateral, tetrahedron and hexahedron elements</li> <li>Hyperelastic material models</li> <li>Saint-Venant Kirchhoff</li> <li>Stable Neo-Hookean</li> <li>Polynomial quadrature rules</li> <li>Simplices in dimensions <code>1,2,3</code></li> <li>Gauss-Legendre quadrature</li> <li>Spatial query acceleration data structures</li> <li>Bounding volume hierarchy for triangles (2D+3D) and tetrahedra (3D)<ul> <li>Nearest neighbours</li> <li>Overlapping primitive pairs</li> <li>Point containment</li> </ul> </li> <li>GPU algorithms</li> <li>Vertex Block Descent (VBD)</li> <li>eXtended Position Based Dynamics (XPBD)</li> <li>Broad phase collision detection<ul> <li>Sweep and Prune</li> <li>Linear Bounding Volume Hierarchy</li> </ul> </li> <li>Fixed-size linear algebra library for kernel programming</li> <li>Seamless profiling integration via Tracy</li> </ul> <p>Currently, the <code>master</code> branch may contain breaking changes at any point in time. We recommend users to use specific git tags, i.e. via <code>git checkout v&lt;major&gt;.&lt;minor&gt;.&lt;patch&gt;</code>, where the version <code>&lt;major&gt;.&lt;minor&gt;.&lt;patch&gt;</code> matches the installed <code>pbatoolkit</code>'s version downloaded from PyPI (i.e. from <code>pip install pbatoolkit</code>).</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Quick start</li> <li>C++</li> <li>Python</li> <li>Tutorial</li> <li>Dependencies</li> <li>CUDA</li> <li>Configuration</li> <li>Build &amp; Install</li> <li>C++</li> <li>Python</li> <li>Install</li> <li>Gallery</li> </ul>"},{"location":"#quick-start","title":"Quick start","text":"<p>We recommend downloading the Tracy profiler server to analyze execution of PBAT algorithms, available as precompiled executable. PBAT currently supports Tracy 0.10.</p>"},{"location":"#c","title":"C++","text":"<p>Take a look at the unit tests, found in the library's source (<code>.cpp</code> or <code>.cu</code>) files.</p>"},{"location":"#python","title":"Python","text":"<p>To download and install from PyPI, run in command line <pre><code>pip install pbatoolkit\n</code></pre> or, alternatively <pre><code>pip install pbatoolkit-gpu\n</code></pre> if your environment is properly setup to use our GPU algorithms.</p> <p>Verify <code>pbatoolkit</code>'s contents in a Python shell</p> <pre><code>import pbatoolkit as pbat\nhelp(pbat.fem)\nhelp(pbat.geometry)\nhelp(pbat.profiling)\nhelp(pbat.math)\nhelp(pbat.gpu)\n</code></pre> <p>A bunch of Python scripts demonstrating usage of <code>pbatoolkit</code> can be found in the examples folder, along with their associated <code>requirements.txt</code>  for easily downloading necessary dependencies via <code>pip install -r path/to/requirements.txt</code>. Their command line interface follows the pattern <pre><code>python[.exe] path/to/examples/[example].py -i path/to/input/mesh\n</code></pre> The full interface is always revealed by <code>-h</code> or <code>--help</code>, i.e.  <pre><code>python[.exe] path/to/examples/[example].py -h\n</code></pre></p> <p>The examples assume the user provides the meshes to <code>pbatoolkit</code>. Triangle (surface) meshes can easily be obtained via Thingi10K, TurboSquid or authored yourself in Blender. Tools like TetWild, fTetWild and TetGen can then convert them into tetrahedral (volume) meshes. We provide helper scripts to facilitate mesh processing and their associated <code>requirements.txt</code>.</p> <p>Example results are showcased in our Gallery.</p>"},{"location":"#tutorial","title":"Tutorial","text":"<p>Head over to our hands-on tutorials section to learn more about physics based animation in both theory and practice!</p>"},{"location":"#dependencies","title":"Dependencies","text":"<p>See <code>vcpkg.json</code> for a versioned list of our dependencies, available via vcpkg.</p> <p>Use of vcpkg is not mandatory, as long as dependencies have compatible versions and are discoverable by CMake's <code>find_package</code> mechanism.</p>"},{"location":"#cuda","title":"CUDA","text":""},{"location":"#pypi","title":"PyPI","text":"<p><code>pbatoolkit-gpu</code> (downloaded from PyPI) requires dynamically linking to an instance of the - CUDA 12 Runtime library, and your - CUDA Driver. </p> <p>Recall that the CUDA Runtime is ABI compatible up to major version.</p> <p>On 64-bit Windows, these are <code>cudart64_12.dll</code> and <code>nvcuda.dll</code>. Ensure that they are discoverable via Windows' DLL search order. We recommend adding <code>&lt;drive&gt;:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.&lt;minor&gt;\\bin</code> (i.e. the binary folder of your CUDA Toolkit installation) to the <code>PATH</code> environment variable. The driver should already be on the search path by default after installation.</p> <p>On Linux, they are <code>libcudart.so.12</code> and <code>libcuda.so.1</code>. Ensure that they are discoverable via Linux's dynamic linker/loader. If they are not already in a default search path, we recommend simply updating the library search path, i.e. <code>export LD_LIBRARY_PATH=\"path/to/driver/folder;path/to/runtime/folder;$LD_LIBRARY_PATH\"</code>.</p> <p>MacOS does not support CUDA GPUs.</p> <p>Our <code>pbatoolkit-gpu</code> prebuilt binaries include PTX, such that program load times will be delayed by JIT compilation on first use. Verify that your NVIDIA GPU supports compute capability at least 7.0. For example, only RTX 2060 up to 4090 chips are supported in the GeForce series. Runtime GPU performance may be constrained by the targeted compute capability.</p>"},{"location":"#local","title":"Local","text":"<p>Consider locally building and installing <code>pbatoolkit</code> against your native GPU for the following reasons. - Achieve optimal GPU performance for your platform. - Support older/newer GPUs and CUDA Toolkit versions.</p>"},{"location":"#configuration","title":"Configuration","text":"Option Values Default Description <code>PBAT_BUILD_PYTHON_BINDINGS</code> <code>ON,OFF</code> <code>OFF</code> Enable <code>PhysicsBasedAnimationToolkit_PhysicsBasedAnimationToolkit</code> Python bindings. Generates the CMake target <code>PhysicsBasedAnimationToolkit_Python</code>, an extension module for Python, built by this project. <code>PBAT_BUILD_TESTS</code> <code>ON,OFF</code> <code>OFF</code> Enable <code>PhysicsBasedAnimationToolkit_PhysicsBasedAnimationToolkit</code> unit tests. Generates the CMake target executable <code>PhysicsBasedAnimationToolkit_Tests</code>, built by this project. <code>PBAT_ENABLE_PROFILER</code> <code>ON,OFF</code> <code>OFF</code> Enable <code>Tracy</code> instrumentation profiling in built <code>PhysicsBasedAnimationToolkit_PhysicsBasedAnimationToolkit</code>. <code>PBAT_PROFILE_ON_DEMAND</code> <code>ON,OFF</code> <code>OFF</code> Activate Tracy's on-demand profiling when <code>PBAT_ENABLE_PROFILER</code> is <code>ON</code>. <code>PBAT_USE_INTEL_MKL</code> <code>ON,OFF</code> <code>OFF</code> Link to user-provided Intel MKL installation via CMake's <code>find_package</code>. <code>PBAT_USE_SUITESPARSE</code> <code>ON,OFF</code> <code>OFF</code> Link to user-provided SuiteSparse installation via CMake's <code>find_package</code>. <code>PBAT_BUILD_SHARED_LIBS</code> <code>ON,OFF</code> <code>OFF</code> Build project's library targets as shared/dynamic. <p>Either run CMake's configure step manually <pre><code>cmake -S &lt;path/to/PhysicsBasedAnimationToolkit&gt; -B &lt;path/to/build&gt; -D&lt;option&gt;=&lt;value&gt; ...\n</code></pre> or, alternatively (and preferably) <pre><code>cmake --preset=&lt;my-favorite-user-preset&gt;\n</code></pre></p> <p>Our project provides configuration presets that capture typical use configurations. For the best experience, install <code>vcpkg</code> and set <code>VCPKG_ROOT=path/to/vcpkg</code> as an environment variable. Then, you can select one of our available presets, for example <code>cmake --preset=default</code>. Refer to the CMake presets documentation for more information.</p>"},{"location":"#build-install","title":"Build &amp; Install","text":""},{"location":"#c_1","title":"C++","text":"<p>Build and install transparently across platforms using the cmake build CLI and cmake install CLI, respectively.</p> <p>Our CMake project exposes the following build targets | Target | Description | |---|---| | <code>PhysicsBasedAnimationToolkit_PhysicsBasedAnimationToolkit</code> | The PBA Toolkit library. | | <code>PhysicsBasedAnimationToolkit_Tests</code> | The test executable, using doctest. | | <code>PhysicsBasedAnimationToolkit_Python</code> | PBAT's Python extension module, using pybind11. |</p> <p>For example, to build tests, run <pre><code>cmake --build &lt;path/to/build/folder&gt; --target PhysicsBasedAnimationToolkit_Tests --config Release\n</code></pre></p> <p>To install PhysicsBasedAnimationToolkit locally, run <pre><code>cd path/to/PhysicsBasedAnimationToolkit\ncmake -S . -B build -D&lt;option&gt;=&lt;value&gt; ...\ncmake --install build --config Release\n</code></pre></p>"},{"location":"#python_1","title":"Python","text":"<p>For a local installation, which builds from source, our Python bindings build relies on Scikit-build-core, which relies on CMake's <code>install</code> mechanism. As such, you can configure the installation as you typically would when using the CMake CLI directly, by now passing the corresponding CMake arguments in <code>pip</code>'s <code>config-settings</code> parameter (refer to the Scikit-build-core documentation for the relevant parameters). See our pyinstall workflow for working examples of building from source on Linux, MacOS and Windows. Then, assuming that external dependencies are found via CMake's <code>find_package</code>, you can build and install our Python package <code>pbatoolkit</code> locally and get the most up to date features. </p> <p>Consider using a Python virtual environment for this step.</p> <p>As an example, assuming use of <code>vcpkg</code> for external dependency management with <code>VCPKG_ROOT=path/to/vcpkg</code> set as an environment variable, run</p> <pre><code>pip install . --config-settings=cmake.args=\"--preset=pip-cuda\" -v\n</code></pre> <p>on the command line to build <code>pbatoolkit</code> from source with GPU algorithms included. Additional environment variables (i.e. <code>CUDA_PATH</code>) and/or CMake variables (i.e. <code>CMAKE_CUDA_COMPILER</code>) may be required to be set in order for CMake to correctly discover and compile against your targeted local CUDA installation. Refer to the CMake documentation for more details.</p>"},{"location":"#gallery","title":"Gallery","text":"<p>Below, we show a few examples of what can be done in just a few lines of code using <code>pbatoolkit</code> and Python. Code can be found here.</p>"},{"location":"#real-time-hyper-elasticity-dynamics","title":"Real-time hyper elasticity dynamics","text":"<p>Our GPU implementation of the eXtended Position Based Dynamics (XPBD) algorithm simulates a ~324k element FEM elastic mesh interactively with contact.</p> <p> </p>"},{"location":"#inter-penetration-free-elastodynamic-contact","title":"Inter-penetration free elastodynamic contact","text":"<p>Combining <code>pbatoolkit</code>'s FEM+elasticity features and the <code>IPC Toolkit</code> results in guaranteed inter-penetration free contact dynamics between deformable bodies.</p> <p> </p>"},{"location":"#modal-analysis","title":"Modal analysis","text":"<p>The hyper elastic beam's representative deformation modes, i.e. its low frequency eigen vectors, are animated as time continuous signals.</p> <p> </p>"},{"location":"#gpu-broad-phase-collision-detection","title":"GPU broad phase collision detection","text":"<p>Real-time collision detection between 2 large scale meshes (~324k tetrahedra) is accelerated by highly parallel implementations of the sweep and prune algorithm, or linear bounding volume hierarchies.</p> <p> </p>"},{"location":"#harmonic-interpolation","title":"Harmonic interpolation","text":"<p>A smooth (harmonic) function is constructed on Entei, required to evaluate to <code>1</code> on its paws, and <code>0</code> at the top of its tail, using piece-wise linear (left) and quadratic (right) shape functions. Its isolines are displayed as black curves.</p> <p> </p>"},{"location":"#heat-method-for-geodesic-distance-computation","title":"Heat method for geodesic distance computation","text":"<p>Approximate geodesic distances are computed from the top center vertex of Metagross by diffusing heat from it (left), and recovering a function whose gradient matches the normalized heat's negative gradient. Its isolines are displayed as black curves.</p> <p> </p>"},{"location":"#mesh-smoothing-via-diffusion","title":"Mesh smoothing via diffusion","text":"<p>Fine details of Godzilla's skin are smoothed out by diffusing <code>x,y,z</code> coordinates in time.</p> <p> </p>"},{"location":"#profiling-statistics","title":"Profiling statistics","text":"<p>Computation details are gathered when using <code>pbatoolkit</code> and consulted in the Tracy profiling server GUI.</p> <p> </p>"},{"location":"#contributing","title":"Contributing","text":""},{"location":"#coding-style","title":"Coding style","text":"<p>A <code>.clang-format</code> description file is provided in the repository root which should be used to enforce a uniform coding style throughout the code base using the clang-format tool. Recent versions of Visual Studio Code and Visual Studio should come bundled with a <code>clang-format</code> installation. On Unix-like systems, <code>clang-format</code> can be installed using your favorite package manager.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#v008-2024-04-22","title":"[v0.0.8] - 2024-04-22","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>New VBD (Vertex Block Descent) implementation on the GPU. Currently does not support contacts.</li> <li>Alternative adaptive initialization strategy for VBD, differing from the strategy proposed in the VBD paper.</li> <li>Nested cage generation tool.</li> <li>Compilation of GPU code included in the CI servers within <code>pyinstall.yml</code>.</li> <li>Split PyPI package into <code>pbatoolkit</code> and <code>pbatoolkit-gpu</code> to facilitate easier usage of GPU features.</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Upgraded the repository's README for improved aesthetics and better documentation on using GPU features.</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>(No fixes in this release)</li> </ul>"},{"location":"changelog/#contributors","title":"Contributors","text":"<ul> <li>@pranavAL made their first contribution in #3.</li> </ul> <p>Full Changelog: v0.0.7...v0.0.8</p>"},{"location":"changelog/#v007-2024-09-18","title":"[v0.0.7] - 2024-09-18","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Incremental Potential Contact (IPC) Python example using <code>pbatoolkit</code> as the elastodynamics engine.</li> <li>Support for optional elastic element Hessian SPD (Symmetric Positive Definite) projections.</li> <li>Parallelized Sweep and Prune GPU implementation for broad phase collision detection.</li> <li>Various C++ utilities for simpler GPU programming (e.g., device buffers, queues, stacks, lists).</li> <li>XPBD (eXtended Position Based Dynamics) implementation on the GPU using stable neo-Hookean constraints and vertex-triangle contact constraints.</li> <li>Parallelized linear BVH (Bounding Volume Hierarchy) data structure on the GPU for broad phase overlap and nearest neighbor queries.</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Allow Windows system search paths to be examined for DLL resolution when importing <code>pbatoolkit</code>.</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>(No fixes in this release)</li> </ul>"},{"location":"changelog/#contributors_1","title":"Contributors","text":"<ul> <li>@pranavAL</li> </ul> <p>Full Changelog: v0.0.6...v0.0.7</p>"},{"location":"changelog/#v006-2024-07-18","title":"[v0.0.6] - 2024-07-18","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Support and tests for optional integration with fast linear solvers (SuiteSparse's Cholmod and Intel MKL's Pardiso). Note: MKL Pardiso is untested and has known errors.</li> <li>Versioned NumPy and SciPy Python dependencies specified in <code>pyproject.toml</code>.</li> <li>Refactored CMake sources to facilitate shared builds, bundle transitive dependencies in Python bindings installation, and expose better CMake configure presets.</li> <li>Enabled on-demand profiling for <code>pbatoolkit</code>.</li> <li>Simplified Python FEM bindings using type erasure to minimize binary size.</li> </ul>"},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>(No changes in this release)</li> </ul>"},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li>(No fixes in this release)</li> </ul> <p>Full Changelog: v0.0.5...v0.0.6</p>"},{"location":"changelog/#v005-2024-07-12","title":"[v0.0.5] - 2024-07-12","text":""},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li>Tutorials on FEM using <code>pbatoolkit</code>.</li> </ul>"},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>Exposed more library internals to make Python scripting more flexible (e.g., quadrature points and weights on mesh, shape function gradients).</li> </ul>"},{"location":"changelog/#fixed_3","title":"Fixed","text":"<ul> <li>(No fixes in this release)</li> </ul> <p>Full Changelog: v0.0.4...v0.0.5</p>"},{"location":"changelog/#v004-2024-07-09","title":"[v0.0.4] - 2024-07-09","text":""},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li>Implemented and tested optional integration with fast linear solvers (SuiteSparse's Cholmod and Intel MKL's Pardiso). Note: MKL Pardiso is untested and has known errors.</li> <li>Specified versioned NumPy and SciPy Python dependencies in <code>pyproject.toml</code>.</li> <li>Refactored CMake sources to facilitate shared builds, bundle transitive dependencies in Python bindings installation, and expose better CMake configure presets.</li> <li>Enabled on-demand profiling for <code>pbatoolkit</code>.</li> <li>Simplified Python FEM bindings using type erasure to minimize binary size.</li> </ul>"},{"location":"changelog/#changed_4","title":"Changed","text":"<ul> <li>(No changes in this release)</li> </ul>"},{"location":"changelog/#fixed_4","title":"Fixed","text":"<ul> <li>(No fixes in this release)</li> </ul> <p>Full Changelog: v0.0.3...v0.0.4</p>"},{"location":"changelog/#v003-2024-06-26","title":"[v0.0.3] - 2024-06-26","text":""},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li>Initial release of <code>pbatoolkit</code> with the following features:</li> <li>FEM utilities (mass matrix, Laplacian, gradient, hyperelastic potential, load) for meshes in dimensions 1, 2, and 3. Supports Lagrange shape functions up to order 3 for line, triangle, quadrilateral, tetrahedral, and hexahedral elements. Note: For non-linear elements such as quads and hexes, shape function gradients and Jacobians may be inaccurate (untested).</li> <li>Efficient sparse matrix construction.</li> <li>Saint-Venant Kirchhoff and Stable Neo-Hookean material models.</li> <li>Axis-aligned Bounding Volume Hierarchies (BVH) for triangles and tetrahedra.</li> <li>Automatic profiling data generation compatible with Tracy.</li> <li>Mostly tested on tetrahedral element meshes; designed to be element-agnostic and dimension-agnostic.</li> <li>Sample code demonstrating the use of <code>pbatoolkit</code> available in the <code>examples</code> folder.</li> </ul>"},{"location":"changelog/#changed_5","title":"Changed","text":"<ul> <li>(No changes in this release)</li> </ul>"},{"location":"changelog/#fixed_5","title":"Fixed","text":"<ul> <li>(No fixes in this release)</li> </ul> <p>Full Changelog: Initial Release</p>"},{"location":"changelog/#contributors_2","title":"Contributors","text":"<ul> <li>@pranavAL - Made their first contribution in #3.</li> </ul>"},{"location":"code_of_conduct/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"code_of_conduct/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"code_of_conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the   overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or   advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email   address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"code_of_conduct/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"code_of_conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"code_of_conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at zfergus@nyu.edu. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"code_of_conduct/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"code_of_conduct/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"code_of_conduct/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"code_of_conduct/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"code_of_conduct/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior,  harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"code_of_conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#coding-style","title":"Coding Style","text":"<p>A <code>.clang-format</code> description file is provided in the repository root which should be used to enforce a uniform coding style throughout the code base using the clang-format tool. Recent versions of Visual Studio Code and Visual Studio should come bundled with a <code>clang-format</code> installation. On Unix-like systems, <code>clang-format</code> can be installed using your favorite package manager.</p>"},{"location":"gallery/","title":"Gallery","text":"<p>Below, we show a few examples of what can be done in just a few lines of code using <code>pbatoolkit</code> and Python. Code can be found here.</p>"},{"location":"gallery/#real-time-hyper-elasticity-dynamics","title":"Real-time Hyper Elasticity Dynamics","text":"<p>Our GPU implementation of the eXtended Position Based Dynamics (XPBD) algorithm simulates a ~324k element FEM elastic mesh interactively with contact.</p> <p> </p>"},{"location":"gallery/#inter-penetration-free-elastodynamic-contact","title":"Inter-penetration Free Elastodynamic Contact","text":"<p>Combining <code>pbatoolkit</code>\u2019s FEM+elasticity features and the <code>IPC Toolkit</code> results in guaranteed inter-penetration free contact dynamics between deformable bodies.</p> <p> </p>"},{"location":"gallery/#modal-analysis","title":"Modal Analysis","text":"<p>The hyper elastic beam's representative deformation modes, i.e., its low frequency eigen vectors, are animated as time continuous signals.</p> <p> </p>"},{"location":"gallery/#gpu-broad-phase-collision-detection","title":"GPU Broad Phase Collision Detection","text":"<p>Real-time collision detection between 2 large scale meshes (~324k tetrahedra) is accelerated by highly parallel implementations of the sweep and prune algorithm, or linear bounding volume hierarchies.</p> <p> </p>"},{"location":"gallery/#harmonic-interpolation","title":"Harmonic Interpolation","text":"<p>A smooth (harmonic) function is constructed on Entei, required to evaluate to <code>1</code> on its paws, and <code>0</code> at the top of its tail, using piece-wise linear (left) and quadratic (right) shape functions. Its isolines are displayed as black curves.</p> <p> </p>"},{"location":"gallery/#heat-method-for-geodesic-distance-computation","title":"Heat Method for Geodesic Distance Computation","text":"<p>Approximate geodesic distances are computed from the top center vertex of Metagross by diffusing heat from it (left), and recovering a function whose gradient matches the normalized heat's negative gradient. Its isolines are displayed as black curves.</p> <p> </p>"},{"location":"gallery/#mesh-smoothing-via-diffusion","title":"Mesh Smoothing via Diffusion","text":"<p>Fine details of Godzilla's skin are smoothed out by diffusing <code>x,y,z</code> coordinates in time.</p> <p> </p>"},{"location":"gallery/#profiling-statistics","title":"Profiling Statistics","text":"<p>Computation details are gathered when using <code>pbatoolkit</code> and consulted in the Tracy profiling server GUI.</p> <p> </p>"},{"location":"license/","title":"License","text":"<p>Boost Software License - Version 1.0 - August 17th, 2003</p> <p>Permission is hereby granted, free of charge, to any person or organization obtaining a copy of the software and accompanying documentation covered by this license (the \"Software\") to use, reproduce, display, distribute, execute, and transmit the Software, and to prepare derivative works of the Software, and to permit third-parties to whom the Software is furnished to do so, all subject to the following:</p> <p>The copyright notices in the Software and this entire statement, including the above license grant, this restriction and the following disclaimer, must be included in all copies of the Software, in whole or in part, and all derivative works of the Software, unless such copies or derivative works are solely in the form of machine-executable object code generated by a source language processor.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"c%2B%2B/configuration/","title":"Configuration","text":""},{"location":"c%2B%2B/configuration/#configuration","title":"Configuration","text":"Option Values Default Description <code>PBAT_BUILD_PYTHON_BINDINGS</code> <code>ON,OFF</code> <code>OFF</code> Enable <code>PhysicsBasedAnimationToolkit_PhysicsBasedAnimationToolkit</code> Python bindings. Generates the CMake target <code>PhysicsBasedAnimationToolkit_Python</code>, an extension module for Python, built by this project. <code>PBAT_BUILD_TESTS</code> <code>ON,OFF</code> <code>OFF</code> Enable <code>PhysicsBasedAnimationToolkit_PhysicsBasedAnimationToolkit</code> unit tests. Generates the CMake target executable <code>PhysicsBasedAnimationToolkit_Tests</code>, built by this project. <code>PBAT_ENABLE_PROFILER</code> <code>ON,OFF</code> <code>OFF</code> Enable <code>Tracy</code> instrumentation profiling in built <code>PhysicsBasedAnimationToolkit_PhysicsBasedAnimationToolkit</code>. <code>PBAT_PROFILE_ON_DEMAND</code> <code>ON,OFF</code> <code>OFF</code> Activate Tracy's on-demand profiling when <code>PBAT_ENABLE_PROFILER</code> is <code>ON</code>. <code>PBAT_USE_INTEL_MKL</code> <code>ON,OFF</code> <code>OFF</code> Link to user-provided Intel MKL installation via CMake's <code>find_package</code>. <code>PBAT_USE_SUITESPARSE</code> <code>ON,OFF</code> <code>OFF</code> Link to user-provided SuiteSparse installation via CMake's <code>find_package</code>. <code>PBAT_BUILD_SHARED_LIBS</code> <code>ON,OFF</code> <code>OFF</code> Build project's library targets as shared/dynamic."},{"location":"c%2B%2B/configuration/#vcpkg-configuration","title":"vcpkg Configuration","text":"<p>The <code>vcpkg.json</code> file defines the dependencies and optional features for the PBAT Toolkit:</p> <ul> <li>Core Dependencies:</li> <li><code>range-v3</code> for range algorithms.</li> <li><code>fmt</code> for string formatting.</li> <li><code>eigen3</code> for linear algebra.</li> <li><code>tbb</code> for parallel programming.</li> <li> <p><code>doctest</code> for testing.</p> </li> <li> <p>Optional Features:</p> </li> <li><code>suitesparse</code>: For sparse matrix operations.</li> <li><code>mkl</code>: For Intel MKL optimized math functions.</li> <li><code>python</code>: To enable Python bindings.</li> <li><code>cuda</code>: To enable CUDA support for GPU acceleration.</li> </ul>"},{"location":"c%2B%2B/configuration/#installing-vcpkg","title":"Installing vcpkg","text":"<p>Open a terminal or command prompt and run:</p> <pre><code>git clone https://github.com/microsoft/vcpkg.git\n</code></pre> <p>After cloning, navigate into the vcpkg directory and run the bootstrap script to build the tool.</p>"},{"location":"c%2B%2B/configuration/#on-linux-and-macos","title":"On Linux and macOS:","text":"<pre><code>cd vcpkg\n./bootstrap-vcpkg.sh\n</code></pre>"},{"location":"c%2B%2B/configuration/#on-windows","title":"On Windows:","text":"<pre><code>cd vcpkg\n.\\bootstrap-vcpkg.bat\n</code></pre>"},{"location":"c%2B%2B/configuration/#setting-up-cmake-presets","title":"Setting up CMake Presets","text":"<p>CMake presets simplify the configuration and build process. Follow these steps to set them up.</p> <p>In the root of your project, create a <code>CMakePresets.json</code> file:</p> <pre><code>{\n    \"version\": 6,\n    \"configurePresets\": [\n        {\n            \"name\": \"dev-msvc-cuda\",\n            \"inherits\": [\"dev\", \"x64\", \"msvc\", \"pic\"],\n            \"cacheVariables\": {\n                \"VCPKG_MANIFEST_FEATURES\": \"python;cuda\",\n                \"PBAT_BUILD_PYTHON_BINDINGS\": {\n                    \"type\": \"BOOL\",\n                    \"value\": \"ON\"\n                },\n                \"PBAT_USE_CUDA\": {\n                    \"type\": \"BOOL\",\n                    \"value\": \"ON\"\n                }\n            }\n        }\n    ]\n}\n</code></pre> <p>You can adjust the settings in <code>CMakePresets.json</code> based on your needs, such as enabling or disabling CUDA or Python bindings.</p>"},{"location":"c%2B%2B/cpp/","title":"C++","text":""},{"location":"c%2B%2B/cpp/#build-install","title":"Build &amp; Install","text":""},{"location":"c%2B%2B/cpp/#c","title":"C++","text":"<p>Build and install transparently across platforms using the cmake build CLI and cmake install CLI, respectively.</p> <p>Our CMake project exposes the following build targets | Target | Description | |---|---| | <code>PhysicsBasedAnimationToolkit_PhysicsBasedAnimationToolkit</code> | The PBA Toolkit library. | | <code>PhysicsBasedAnimationToolkit_Tests</code> | The test executable, using doctest. | | <code>PhysicsBasedAnimationToolkit_Python</code> | PBAT's Python extension module, using pybind11. |</p> <p>For example, to build tests, run <pre><code>cmake --build &lt;path/to/build/folder&gt; --target PhysicsBasedAnimationToolkit_Tests --config Release\n</code></pre></p> <p>To install PhysicsBasedAnimationToolkit locally, run <pre><code>cd path/to/PhysicsBasedAnimationToolkit\ncmake -S . -B build -D&lt;option&gt;=&lt;value&gt; ...\ncmake --install build --config Release\n</code></pre></p>"},{"location":"c%2B%2B/cuda/","title":"CUDA Installation Guide","text":""},{"location":"c%2B%2B/cuda/#what-is-cuda","title":"What is CUDA?","text":"<p>CUDA (Compute Unified Device Architecture) is a parallel computing platform and application programming interface (API) model created by NVIDIA.  It allows developers to use GPUs for general-purpose processing, also known as GPU computing. CUDA is designed to work on NVIDIA GPUs.</p>"},{"location":"c%2B%2B/cuda/#how-to-install-cuda","title":"How to Install CUDA","text":""},{"location":"c%2B%2B/cuda/#1-windows-installation","title":"1. Windows Installation","text":"<p>Follow these steps to install CUDA on Windows:</p> <ol> <li> <p>Check GPU Compatibility    Make sure your system has an NVIDIA GPU that supports CUDA. You can check the list of supported GPUs on the CUDA-Enabled GPUs page.</p> </li> <li> <p>Download the CUDA Toolkit    Visit the official NVIDIA CUDA Toolkit page:    Download CUDA Toolkit for Windows</p> </li> <li> <p>Install CUDA Toolkit    Follow the installation instructions provided by NVIDIA:    Installation Guide for Windows</p> </li> <li> <p>Verify Installation    Once installed, verify CUDA by running the following command in the command prompt:    <pre><code>nvcc --version\n</code></pre></p> </li> </ol>"},{"location":"c%2B%2B/cuda/#2-linux-installation","title":"2. Linux Installation","text":"<p>To install CUDA on Linux, follow these steps:</p> <ol> <li> <p>Check GPU Compatibility    Ensure your system has a supported NVIDIA GPU. Check the list of supported GPUs here: CUDA-Enabled GPUs</p> </li> <li> <p>Download CUDA Toolkit    Visit the official NVIDIA CUDA Toolkit page: Download CUDA Toolkit for Linux</p> </li> <li> <p>Install CUDA Toolkit    Follow the installation guide for Linux: Installation Guide for Linux</p> </li> <li> <p>Verify Installation    After installation, verify by running:    <pre><code>nvcc --version\n</code></pre></p> </li> </ol>"},{"location":"c%2B%2B/cuda/#3-macos-users","title":"3. macOS Users","text":"<p>As of now, CUDA is not supported on macOS. NVIDIA stopped supporting CUDA for macOS after macOS 10.13 (High Sierra). If you are using a Mac, you won't be able to run CUDA applications natively, as Apple transitioned to its own GPUs (M1, M2) and discontinued official NVIDIA support.</p> <p>However, if you need to work with CUDA, here are some alternatives: - Use a Cloud Service: Platforms like Google Colab or AWS EC2 with GPU instances provide remote access to GPUs with CUDA support. - Use a Linux or Windows Virtual Machine (VM): Run a Linux or Windows VM on your Mac using software like VirtualBox or Parallels Desktop, and install CUDA inside the VM (performance may vary).</p> <p>For more details on CUDA-supported platforms and GPUs, visit: NVIDIA CUDA Toolkit Official Site</p>"},{"location":"course/fem/","title":"The Finite Element Method","text":""},{"location":"course/fem/boundary_conditions/","title":"Boundary Conditions","text":""},{"location":"course/fem/boundary_conditions/#boundary-conditions","title":"Boundary conditions","text":"<p>Neumann boundary conditions are imposed values on the gradient of the problem's solution. These Neumann boundary conditions are often called \"natural\" boundary conditions, because they are implicitly encoded in the problem (where a laplacian appears) and appear \"naturally\" when applying Green's identities (see previous subsection), i.e. we can enforce them simply by introducing an extra forcing vector in the discretized linear system.</p> <p>Dirichlet boundary conditions, i.e. \"essential\" boundary conditions, are imposed on the problem's solution itself (as opposed to its derivatives) and are necessary to make our PDEs well-determined (i.e. not rank-deficient). It is often the case that we can impose Dirichlet boundary conditions directly on the FEM mesh's nodes \\(i\\), by simply constraining its associated coefficients \\(u_i = d_i\\) for some known value \\(d_i\\). This is the same as saying, in the continuous case, that \\(u(X_i) = d_i\\). Because of the Kronecker delta property on FEM basis functions, \\(u(X_i) = u_i \\phi_i(X_i) = u_i\\), and so \\(u_i = d_i\\) for Dirichlet constrained nodes. This approach makes it particularly easy to enforce Dirichlet boundary conditions numerically, as it essentially removes degrees of freedom out of a matrix equation. Consider the linear system \\(Ax=b\\) discretizing some problem via FEM. Assume that the vector \\(x\\) has been partitioned into a vector of unknowns \\(x_u\\) and known values \\(x_k = d_k\\) for Dirichlet imposed values \\(d_k\\). The same partitioning may be applied to the rows and columns of matrix \\(A\\) and similarly to the right-hand side vector \\(b\\). We thus get that </p> \\[ \\begin{bmatrix}  A_{uu} &amp; A_{uk} \\\\  A_{ku} &amp; A_{kk}  \\end{bmatrix}  \\begin{bmatrix}   x_u \\\\  x_k  \\end{bmatrix} =  \\begin{bmatrix}  b_u \\\\  b_k  \\end{bmatrix} . \\] <p>The unknowns are thus obtained by solving a reduced problem</p> \\[ A_{uu} x_u = b_u - A_{uk} d_k . \\] <p>The matrix \\(A_{uu}\\) preserves symmetry if \\(A\\) is symmetric, and similarly for positive (or negative) (semi-)definiteness.</p> <p>In the general case, however, it might be the case that Dirichlet boundary conditions cannot be imposed at the nodes. In this case, we might need to enforce Dirichlet boundary conditions as constraints to an optimization problem. For example, our discretized Poisson problem could become the equality constrained minimization</p> \\[ Au = f \\longrightarrow \\min_u \\frac{1}{2}||Au - f||_2^2  \\quad\\text{ s.t. }\\quad Du_D - d_D = 0 , \\] <p>where \\(Du_D - d_D = 0\\) discretizes the continuous constraint \\(\\int_{\\partial \\Omega^D} u(X) \\partial S - d(X) = 0\\) using FEM.</p>"},{"location":"course/fem/boundary_conditions/#vector-valued-functions","title":"Vector-valued functions","text":"<p>In many cases, we might want to discretize vector-valued functions using FEM. For example, we might want to model some displacement field in the domain, as is the case in elasticity/deformation. Suppose that \\(u(X): \\Omega \\longrightarrow \\mathbb{R}^d\\) for some \\(d\\), i.e. \\(u(X)\\) maps domain positions to some \\(d\\)-dimensional quantity. In this case, we can simply consider each scalar component \\(u_k(X)\\) of \\(u(X)\\) as a function. Thus, we can discretize each \\(u_k(X)\\) using FEM and obtain \\(d\\) coefficient vectors \\(u_k \\in \\mathbb{R}^n\\). All the operators that we have already defined can then directly be applied to each \\(u_k\\) independently. In matrix notation, we may horizontally stack the \\(u_k\\) as columns into some matrix \\(U \\in \\mathbb{R}^{n \\times d}\\), and multiply \\(U\\) from the left using operators \\(M,L,G\\). The product \\(LU\\) would compute the Laplacian of each scalar component \\(u_k(X)\\) of \\(u(X)\\), while \\(GU\\) would compute their gradients. The load vector can similarly be defined as considering each \\(u_k(X)\\) as its own separate forcing function, resulting in a matrix \\(F \\in \\mathbb{R}^{n \\times d}\\) after discretization.</p> <p>In other situations, however we may wish to concatenate the coefficients \\(u_k\\) into a single vector \\(u \\in \\mathbb{R}^{nd}\\). This leads to 2 options:</p> <ol> <li>Stack each \\(u_k\\) vertically.</li> <li>Interleave all the \\(u_k\\).</li> </ol> <p>By interleaving, we mean that if the \\(k^{\\text{th}}\\) coefficient vector \\(u_k\\) has coefficients \\(u_{ik}\\), then the resulting \"interleaved\" vector \\(<code>u = \\begin{bmatrix} u_{11} &amp; \\dots &amp; u_{n1} &amp; \\dots &amp; u_{1d} &amp; \\dots &amp; u_{nd} \\end{bmatrix}^T</code>\\). Practically, this just means that option 1 flattens the matrix \\(U \\in \\mathbb{R}^{n \\times d}\\) by stacking its column vertically, and option 2 flattens \\(U\\) by stacking its transposed rows vertically. For both options, our FEM operators \\(M,L,G\\) can adjust to \\(u\\) by using the Kronecker product. Our new operators \\(A = M, L, G\\) take the following forms for the corresponding options </p> <ol> <li>\\(A_{nd \\times nd} = I_{d \\times d} \\otimes A\\) </li> <li>\\(A_{nd \\times nd} = A \\otimes I_{d \\times d}\\) </li> </ol> <p>The new load vector \\(f \\in \\mathbb{R}^{nd}\\) can be obtained from \\(F\\) in the same way as \\(u\\) was obtained from \\(U\\).</p> <p>In the continuous setting, FEM discretized functions (i.e. solution, forcing function, etc.) are now written in the following equivalent forms</p> \\[ u(X) = \\sum_i \\left[I_{d \\times d} \\otimes \\phi_i(X)\\right] u_i = \\sum_i \\phi_i(X) u_i, \\] <p>and their gradients/jacobians become </p> \\[ \\nabla u(X) = \\sum_i u_i \\nabla \\phi_i(X) , \\] <p>where \\(u_i\\) is a column vector, while the gradient \\(\\nabla \\phi_i(X)\\) is a row vector, i.e. \\(u_i \\nabla \\phi_i(X)\\) is their outer product.</p>"},{"location":"course/fem/introduction/","title":"The Finite Element Method","text":""},{"location":"course/fem/introduction/#introduction","title":"Introduction","text":"<p>The Finite Element Method (FEM) is an approach to discretizing space-dependent continuous problems defined on geometrically \"complex\" domains. As opposed to Finite Differences (FD), which is restricted to regular grid domains, FEM relies on meshing the problem's domain (geometric discretization), describing the problem's solution as a linear combination of piece-wise (i.e., per mesh element) interpolating polynomials (functional discretization), and solving the approximated problem on the mesh. The \"Finite\" in FEM comes from limiting the approximate solution to be spanned by a \"finite-dimensional\" functional basis, i.e., the one spanned by the element-wise interpolating polynomials (the basis functions). The \"Element\" in FEM comes from the polynomials being entirely constructed/defined by the simple geometric primitives composing the mesh, called \"elements\".</p> <p> </p> <p>Geometric mesh (left) vs FEM mesh with linear (middle) and quadratic (right) Lagrange elements.</p> <p>With \\(n=|I|\\), FEM restricts \\(u(X)\\) to the class of functions \\(u(X) = \\sum_{i=1}^{n} u_i \\phi_i(X)\\), i.e., linear combinations of coefficients \\(u_i\\) and basis functions \\(\\phi_i\\) associated with nodes \\(i\\). More compactly, \\(u(X) = \\Phi^T u\\), where \\(u = \\begin{bmatrix}u_1 &amp; \\dots &amp; u_{n} \\end{bmatrix}^T \\in \\mathbb{R}^{n}\\) and \\(\\Phi = \\begin{bmatrix} \\phi_1(X) &amp; \\dots &amp; \\phi_{n}(X) \\end{bmatrix}^T \\in \\mathbb{R}^{n}\\). We say that the basis functions \\(\\phi_i\\) span the function space \\(\\{ \\Phi^T u \\;\\forall\\; u \\in \\mathbb{R}^{n} \\}\\), much like basis vectors \\(v_i\\) span vector spaces \\(V\\). Functions in the FEM function space, i.e., the space spanned by \\(\\phi_i\\), are uniquely represented by their vector of coefficients \\(u\\), much like vectors \\(v = v_1 \\overrightarrow{i} + v_2\\overrightarrow{j} + v_3 \\overrightarrow{k}\\) in \\(\\mathbb{R}^3\\) are uniquely represented by their coefficients \\(\\begin{bmatrix} v_1 &amp; v_2 &amp; v_3 \\end{bmatrix}\\). </p> <p> </p> <p>FEM function space in 1D using linear hat basis functions.</p> <p>Such a discrete functional representation allows one to accurately map continuous problems from theory onto computers by needing only to store the discrete and finite-dimensional coefficients \\(u\\) and FEM mesh \\((I,E)\\), assuming an appropriate geometric meshing of the problem domain is readily available. Furthermore, the linearity of \\(u(X)\\) w.r.t. \\(\\Phi\\) naturally translates solving FEM-discretized problems into solving matrix equations.</p>"},{"location":"course/fem/introduction/#prerequisites","title":"Prerequisites","text":"<ul> <li>Calculus</li> <li>Linear Algebra</li> <li>Differential equations (optional)</li> </ul>"},{"location":"course/fem/limitations/","title":"Limitations","text":""},{"location":"course/fem/limitations/#limitations","title":"Limitations","text":"<p>While FEM remains an invaluable tool for scientific computing, it is not without its drawbacks. One of its main drawbacks is FEM's reliance on an appropriate meshing of the domain. Indeed, for FEM discretized problems to be well-conditioned, its element geometries must be \"regular\". The well-known paper What is a good linear finite element? details this phenomenon in depth. Current meshing tools may take enormous amounts of computational resources (memory, runtime) to produce acceptable outputs. Additionally, it is not guaranteed that any domain can be meshed with current tools. In the realm of computer graphics, geometries are extremely complex, i.e. they exhibit fine details, are high resolution, have highly varying structural qualities (like thin structures, high curvatures) in different regions, and may be poorly authored (among other potential obstacles). In such cases, current tools may break down, or FEM will likely struggle with the quality of their output. Even if high quality meshes of such complex geometries are obtained, their resolution may be so high that solving linear systems of equations arising from FEM will be extremely slow. Modern approaches such as Monte Carlo Geometry Processing and its extensions, Monte Carlo Fluids tackle this exact problem. Meshless methods also exist to sidestep the mesh generation preprocess to FEM, among other such alternative approaches that I am simply not aware of. In the particular case of triangle mesh FEM, intrinsic triangulations also enable a high level of robustness to mesh ill-conditioning.</p>"},{"location":"course/fem/method/","title":"Method","text":"<p>Given some space-dependent problem whose solution \\(u(X)\\) is defined on some  continuous domain \\(\\Omega\\), FEM first requires a geometric mesh \\((V,C) \\approx \\Omega\\), where \\(C\\) is a set of cells whose vertices are in \\(V\\). From \\((V,C)\\), we then construct the FEM mesh \\((I,E)\\), where \\(I\\) is the set of FEM nodes and \\(E\\) is the set of FEM elements. We now assume that the geometric mesh is the domain itself \\((V,C)=\\Omega\\).</p> <p>Nodes \\(i \\in I\\) have corresponding positions \\(X_i \\in \\Omega\\) and associated basis functions \\(\\phi_i(X): \\Omega \\longrightarrow \\mathbb{R}\\) such that \\(\\phi_i(X_j) = \\delta_{ij}\\), where \\(\\delta_{ij}\\) is the Kronecker delta. Such basis functions are defined element-wise by so-called shape functions \\(N_i^e(X)\\) for pairs \\((i,e)\\) of adjacent node and element, and vanish in non-adjacent elements. In other words, the support of \\(\\phi_i(X)\\) is the union of its adjacent elements, and evaluating \\(\\phi_i(X)\\) amounts to finding the element \\(e\\) containing the evaluation point \\(X\\), and evaluating \\(N_i^e(X)\\) there. It is common to refer to this choice of basis function \\(\\phi_i(X)\\) as the \"hat\" function, because its tip (i.e. its maximal value of \\(1\\)) is located on node \\(i\\), \"centered\" in its support, while it smoothly decreases to 0 at surrounding nodes. It is also common to refer to these elements as \"PK Lagrange elements\", because their shape functions \\(N_i^e(X)\\) are interpolating polynomials of degree \\(K\\).</p> Geometric mesh (left) versus FEM meshes discretized with linear (middle) and quadratic (right) Lagrange elements. <p>With \\(n=|I|\\), FEM restricts \\(u(X)\\) to the class of functions \\(u(X) = \\sum_{i=1}^{n} u_i \\phi_i(X)\\), i.e. linear combinations of coefficients \\(u_i\\) and basis functions \\(\\phi_i\\) associated with nodes \\(i\\). More compactly, \\(u(X) = \\Phi^T u\\), where \\(<code>u = \\begin{bmatrix}u_1 &amp; \\dots &amp; u_{n} \\end{bmatrix}^T \\in \\mathbb{R}^{n}</code>\\) and \\(<code>\\Phi = \\begin{bmatrix} \\phi_1(X) &amp; \\dots &amp; \\phi_{n}(X) \\end{bmatrix}^T \\in \\mathbb{R}^{n}</code>\\). We say that the basis functions \\(\\phi_i\\) span the function space \\(<code>\\{ \\Phi^T u \\;\\forall\\; u \\in \\mathbb{R}^{n} \\}</code>\\), much like basis vectors \\(v_i\\) span vector spaces \\(V\\). Functions in the FEM function space, i.e. the space spanned by \\(\\phi_i\\), are uniquely represented by their vector of coefficients \\(u\\), much like vectors \\(v = v_1 \\overrightarrow{i} + v_2\\overrightarrow{j} + v_3 \\overrightarrow{k}\\) in \\(\\mathbb{R}^3\\) are uniquely represented by their coefficients \\(<code>\\begin{bmatrix} v_1 &amp; v_2 &amp; v_3 \\end{bmatrix}</code>\\). </p> FEM function space in 1D using linear \"hat\" basis functions. <p>Such a discrete functional representation allows one to accurately map continuous problems from theory onto computers by needing only to store the discrete and finite-dimensional coefficients \\(u\\) and FEM mesh \\((I,E)\\), assuming an appropriate geometric meshing of the problem domain is readily available. Furthermore, the linearity of \\(u(X)\\) w.r.t. \\(\\Phi\\) naturally translates solving FEM-discretized problems into solving matrix equations.</p>"},{"location":"course/fem/method/#summary","title":"Summary","text":"<p>Basis functions \\(\\phi_i(X)\\) are constructed piece-wise in mesh elements \\(e\\) adjacent to node \\(i\\) via element shape functions \\(N_i^e(X)\\). To evaluate \\(\\phi_i(X)\\), we find element \\(e\\) adjacent to node \\(i\\) containing point \\(X\\), and evaluate \\(N_i^e(X)\\). The shape functions are polynomials which depend on the geometry of their associated element, and we compute them by inverting a matrix \\(P^T\\) of polynomials evaluated at element \\(e\\)'s nodes. To avoid ill-conditioning of the matrix inversion problem, we instead define a reference element that is well-conditioned, and construct reference shape functions \\(N_l(\\xi)\\) there. Evaluating our basis functions in the domain then amounts to \\(\\phi_i(X) = N_i^e(X) = N_l(\\xi(X))\\), where \\(\\xi(X)\\) is the inverse map taking domain positions \\(X\\) to reference positions \\(\\xi\\), as opposed to the map \\(X(\\xi)\\) which takes reference positions to domain positions. Gradients of basis functions can be computed by carrying out the chain rule of differentiation through \\(N_l(\\xi)\\) and \\(\\xi(X)\\). The specific placement of nodes and the associated basis polynomials in reference space defines the type of an FEM element. We present the classic Lagrange element as a simple yet popular choice.</p> <p>Because functions discretized on an FEM mesh have a linear combination structure \\(u(X) \\approx \\Phi^T u\\), and \\(u\\) is a simple vector of constant (with respect to \\(X\\)) coefficients, differential operators \\(D(\\cdot)\\) applied to \\(u(X)\\) need only be applied to the basis functions \\(\\phi_i(X)\\) by linearity. In other words, \\(L(u(X)) = \\sum_i u_i L(\\phi_i(X))\\). Hence, the gradient \\(\\nabla u(X)\\), for example, amounts to \\(\\sum_i u_i \\nabla \\phi_i(X)\\), where we have shown how to evaluate \\(\\nabla \\phi_i(X)\\). The same applies to other differential operators, such as \\(\\Delta, \\nabla^2, \\nabla \\cdot, \\int \\partial\\), etc.</p>"},{"location":"course/fem/method/#motivation","title":"Motivation","text":"<p>As a motivating example, consider a well-known partial differential equation (PDE), the Poisson equation, </p> \\[ \\Delta u(X) = f(X) , \\] <p>defined on some domain \\(\\Omega\\), where \\(\\Delta\\) is the Laplacian and \\(f(X)\\) is some known function in space. In other words, we wish to solve for some function \\(u(X)\\) whose Laplacian is given by \\(f(X)\\) everywhere in \\(\\Omega\\) (i.e. \\(<code>\\;\\forall\\; X \\in \\Omega</code>\\)). Without further analytical specification on the domain \\(\\Omega\\), there is little we can do to solve such a general problem. In fact, most domains that we care about and that appear in real life don't have an analytical description. Even if we did have such a description of the domain, it might still be very hard to solve such a problem by hand. We do, however, have powerful meshing tools which can take human-authored complex geometry as input, and produce meshes that accurately approximate the domain as output. ...</p>"},{"location":"course/fem/operators/","title":"Operators","text":""},{"location":"course/fem/operators/#operators","title":"Operators","text":"<p>Now that we know how to compute shape functions, their derivatives and their integrals, we present a handful of useful FEM operators used to discretize common problems.</p>"},{"location":"course/fem/operators/#shape-function-matrix","title":"Shape function matrix","text":"<p>Our first operator will simply evaluate an FEM function \\(u(X)\\) at every quadrature point \\(X(\\xi_g)\\) in every element \\(e\\), where \\(X(\\cdot)\\) is to be understood as element \\(e\\)'s map from the reference element to the domain. Given \\(u(\\cdot)\\)'s coefficient vector \\(u\\), we thus wish to compute \\(u(X(\\xi_g)) = \\sum_i u_i \\phi(X(\\xi_g)) = \\Phi(X(\\xi_g))^T u\\) for every element \\(e\\) and every quadrature point \\(\\xi_g\\) in the reference element. However, we know that \\(\\phi_i(X(\\xi_g))\\) is only non-zero when node \\(i\\) is part of element \\(e\\), so we can safely ignore (i.e. set to zero) all \\(\\phi_j(X(\\xi_g))\\) for nodes \\(j\\) not in element \\(e\\). In other words, only the shape functions of element \\(e\\) need to be evaluated at quadrature points in \\(e\\). This results in a highly sparse operator \\(N\\), whose (sparse) block rows \\(N_e\\) are defined as </p> \\[ N_e = \\begin{bmatrix} \\phi_1(X(\\xi_1)) &amp; \\dots &amp; \\phi_n(X(\\xi_1)) \\\\ \\vdots &amp; \\vdots &amp; \\vdots \\\\ \\phi_1(X(\\xi_q)) &amp; \\dots &amp; \\phi_n(X(\\xi_q)) \\\\ \\end{bmatrix} \\in \\mathbb{R}^{q \\times n} , \\] <p>where \\(q\\) is the number of quadrature points and \\(n\\) is the number of FEM nodes. Compact storage of \\(N_e\\) would store only the shape function values \\(<code>\\begin{bmatrix} N_l^e(X(\\xi_g)) \\end{bmatrix} \\in \\mathbb{R}^{q \\times n^e}</code>\\) in a dense matrix using local node indexing \\(l\\). These local dense matrices are often named using the prefix \"element\", as in \"element shape function matrix\", or \"element hessian\" and so on and so forth.</p> <p>Our full shape function matrix \\(N \\in \\mathbb{R}^{|E|q \\times n}\\) is thus sparse, and its application to \\(u\\)  computes \\(u(X^e(\\xi_g))\\), yielding a vector \\(N u \\in \\mathbb{R}^{|E|q \\times 1}\\).</p>"},{"location":"course/fem/operators/#quadrature-matrix","title":"Quadrature matrix","text":"<p>We introduce a second operator that will enable computing integrals of FEM quantities using matrix operations. Recall from the section on spatial integration that using numerical quadrature, any integral in any element \\(e\\) with polynomial integrands of order \\(p\\) can be computed exactly given the quadrature weights \\(w_g\\) and the jacobian determinants \\(|\\det \\nabla_\\xi X(\\xi_g)|\\) for a polynomial quadrature rule \\((w_g, \\xi_g)\\) of order greater than or equal to \\(p\\). Hence, any integrand evaluated at \\(X(\\xi_g)\\) simply needs to be multiplied by \\(w_g |\\det \\nabla_\\xi X(\\xi_g)|\\) to be integrated. This hints at the diagonal matrix \\(Q \\in \\mathbb{R}^{|E|q \\times |E|q}\\), which we will name the \"Quadrature\" matrix, whose diagonal blocks are </p> \\[ Q_e = \\begin{bmatrix} w_1 |\\det \\nabla_\\xi X(\\xi_1)| &amp; 0 &amp; 0 \\\\ 0 &amp; \\ddots &amp; 0 \\\\ 0 &amp; 0 &amp; w_q |\\det \\nabla_\\xi X(\\xi_q)| \\\\ \\end{bmatrix} \\in \\mathbb{R}^{q \\times q}  \\] <p>for every element \\(e\\).</p> <p>This quadrature matrix \\(Q\\) is essentially a discrete analog of the inner product \\(\\langle u, v \\rangle = \\int_\\Omega u v \\partial \\Omega\\) of functions \\(u, v\\) defined on the FEM mesh. For instance, the volume of each domain can be computed easily by the inner product of the unit function, i.e. \\(\\langle 1, 1 \\rangle = \\int_\\Omega \\partial \\Omega = 1_{|E|q}^T Q 1_{|E|q}\\), where we have used the vector of all ones \\(1_{|E|q} \\in \\mathbb{R}^{|E|q}\\). The volume of individual elements \\(e\\) can similarly be computed as $\\left[  I_{|E| \\times |E|} \\otimes 1_{q} \\right]^T Q \\left[  I_{|E| \\times |E|} \\otimes 1_{q} \\right] $, where \\(\\otimes\\) is the Kronecker product.</p> <p>Galerkin projections \\(\\langle f, \\phi \\rangle\\) also become easy to compute. Consider some function \\(f\\) discretized at element quadrature points into matrix \\(F\\), then we can compute its Galerkin projection as \\(N^T Q F\\). </p>"},{"location":"course/fem/operators/#load-vector","title":"Load vector","text":"<p>In the motivating example, we showed how the Poisson equation \\(\\Delta u(X) = f(X)\\) became a linear system \\(Au=f\\) after FEM discretization, where \\(f_i = \\int_{\\Omega} f(X) \\phi_i(X) \\partial \\Omega\\). However, this form is impractical, because for every different forcing function \\(f(X)\\), a different integral expression would have to be generated to compute \\(f\\). Instead, we will often discretize \"known\" forcing functions, i.e. load vectors, as these piece-wise (per element) polynomial functions \\(f(X) = f_e(X) \\in \\mathbb{R}^{d}\\) for \\(X \\in \\Omega^e\\). This allows us to compute the load vector \\(f\\) as</p> \\[ f_i = \\int_{\\Omega} f(X) \\phi_i(X) \\partial \\Omega = \\sum_e \\int_{\\Omega^e} f_e(X) \\phi_i(X) \\partial \\Omega^e , \\] <p>since the \\(f_e(X)\\) are polynomial in their corresponding element. If \\(f_e(X)\\) has order \\(p_f\\) and \\(\\phi_i(X)\\) is of order \\(p_\\phi\\), then a polynomial quadrature rule of order \\(p=p_f + p_\\phi\\) is exact, and we obtain </p> \\[ \\int_{\\Omega^e} f_e(X) \\phi_i(X) \\partial \\Omega^e = \\sum_g \\left[ w_g |\\det \\nabla_\\xi X(\\xi_g)| \\right] f_e(X(\\xi_g)) \\phi_i(X(\\xi_g)) . \\] <p>We can thus construct the matrix \\(F \\in \\mathbb{R}^{|E|q \\times d}\\), whose block rows \\(F_e \\in \\mathbb{R}^{q \\times d}\\) contain values of the forcing function \\(f_e\\) evaluated at \\(e\\)'s quadrature points \\(X(\\xi_g)\\), and compute the load vector \\(f\\) under Galerkin projection as </p> \\[ f = N^T Q F \\in \\mathbb{R}^{n \\times d}  \\] <p>with exact integration, given a quadrature matrix \\(Q\\) discretized for order \\(p\\) integrands.</p> <p>In the special case that \\(f(X)\\) is piece-wise constant, the element integrals become \\(f_e(X) \\int_{\\Omega^e} \\phi_i(X) \\partial \\Omega^e\\) in each element, such that \\(\\int_{\\Omega^e} \\phi_i(X) \\partial \\Omega^e\\) can instead be precomputed and re-used for any new piece-wise constant forcing function \\(f(X) = f_e(X)\\). In this case, \\(p = p_\\phi\\), and basis function integrals \\(\\int_{\\Omega^e} \\phi_i(X) \\partial \\Omega^e\\) are precomputed into \\(B = N^T Q 1_{|E|q}\\). Then, different load vectors can be computed for any piece-wise constant function \\(f(X) = f_e(X)\\) discretized in \\(F\\) for a quadrature order \\(p\\) as </p> \\[ f = B F \\in \\mathbb{R}^{n \\times d} . \\]"},{"location":"course/fem/operators/#mass-matrix","title":"Mass matrix","text":"<p>Another approach is to directly discretize the forcing function \\(f(X) \\approx \\sum_j f_j \\phi_j(X)\\) in the same function space as the FEM solution. Under the Galerkin projection, we would thus get </p> \\[ \\int_{\\Omega} f(X) \\partial \\Omega = \\sum_j f_j \\int_{\\Omega} \\phi_i(X) \\phi_j(X) \\partial \\Omega . \\] <p>In matrix notation, this is exactly \\(Mf\\), where \\(M \\in \\mathbb{R}^{n \\times n}\\) and \\(f \\in \\mathbb{R}^{n \\times 1}\\) and the entries \\(M_{ij} = \\int_{\\Omega} \\phi_i(X) \\phi_j(X) \\partial \\Omega\\). The forcing function \\(f(X)\\) may thus be user-defined purely by specifying function values \\(f_i\\) at the mesh nodes \\(i\\), rather than at mesh elements \\(e\\) as in the previous section. If \\(\\phi_i(X)\\) is a polynomial of order \\(p\\), then mass matrix entries have polynomial integrands of order \\(2p\\). Thus, the mass matrix can be computed exactly using a polynomial quadrature rule of order \\(2p\\).</p> <p>Using this approach, the earlier Poisson problem would be discretized into \\(Au = Mf\\). Many other PDEs involving known functions make the mass matrix appear. The dot product \\(u(X)^T v(X)\\) of 2 functions \\(u(X) = \\sum_i u_i \\phi_i(X)\\) and \\(v(X) = \\sum_i v_i \\phi_i(X)\\) discretized in FEM's solution space, with coefficients vectors \\(u\\) and \\(v\\), will similarly make the mass matrix appear as \\(u(X)^T v(X) = u^T M v\\). We can thus think of the mass matrix as a suitable inner product matrix which enjoys the desirable property of being symmetric and positive definite.</p> <p>Again, because each element uniquely contributes to its nodes' basis function integrals, we can compute and store per-element mass matrices independently as </p> \\[ M^e =  \\begin{bmatrix}  \\int_{\\Omega^e} \\phi_1 \\phi_1 \\partial \\Omega^e &amp; \\dots &amp; \\int_{\\Omega^e} \\phi_1 \\phi_{n^e} \\partial \\Omega^e \\\\  \\vdots &amp;  &amp; \\vdots \\\\  \\int_{\\Omega^e} \\phi_{n^e} \\phi_1 \\partial \\Omega^e &amp; \\dots &amp; \\int_{\\Omega^e} \\phi_{n^e} \\phi_{n^e} \\partial \\Omega^e  \\end{bmatrix} , \\] <p>using local node indices \\(l=1,2,\\dots,n^e\\) which are then accumulated (i.e. summed) into the global mass matrix \\(M\\) by mapping local indices \\(l\\) into corresponding global indices \\(i\\) and \\(j\\) for rows and columns. We call these the element mass matrices.</p> <p>It is possible to associate physical meaning to the mass matrix by injecting into its integral form a measure of mass density \\(\\rho\\) (i.e. grams per unit volume). If the mass density is specified as piece-wise constants (per element) \\(\\rho_e\\), then we simply scale each element mass matrix as \\(\\rho_e M^e\\) and sum the scaled element mass matrices into the global mass matrix \\(M\\).</p> <p>If we use our previously defined quadrature matrix \\(Q\\) and shape function matrix \\(N\\) of quadrature order \\(2p\\), then we can simply write</p> \\[ M = N^T Q N \\in \\mathbb{R}^{n \\times n} . \\] <p>With this construction, the inner product structure of \\(M\\) is even more obvious. The product \\(u^T M v = u^T N^T Q N v\\) immediately reveals that we are integrating \\(\\langle u, v \\rangle\\) for functions \\(u, v\\) discretized on the mesh using shape functions \\(N\\).</p>"},{"location":"course/fem/operators/#gradient-matrix","title":"Gradient matrix","text":"<p>Computing the gradient \\(\\nabla u(X)\\) amounts to simply \\(\\sum_i u_i \\nabla \\phi_i(X)\\). This leads to defining \\(G\\) similarly to \\(N\\), except we now inject the shape function derivatives \\(\\frac{\\partial \\phi_i(X(\\xi_g))}{\\partial X_k}\\) for the \\(k^\\text{th}\\) dimension, evaluated at element \\(e\\)'s quadrature points \\(X(\\xi_g)\\), in the \\(e^{\\text{th}}\\) block row.</p> <p>This leads to defining the Galerkin gradient matrix for \\(X\\) of dimensions \\(d\\) via its block rows, as </p> \\[ G^k_{e} = \\begin{bmatrix} \\frac{\\partial \\phi_1(X(\\xi_1))}{\\partial X_k} &amp; \\dots &amp; \\frac{\\partial \\phi_n(X(\\xi_1))}{\\partial X_k} \\\\ \\vdots &amp; \\ddots &amp; \\vdots\\\\ \\frac{\\partial \\phi_1(X(\\xi_q))}{\\partial X_k} &amp; \\dots &amp; \\frac{\\partial \\phi_n(X(\\xi_q))}{\\partial X_k} \\\\ \\end{bmatrix} \\in \\mathbb{R}^{q \\times n}. \\] <p>As in the case of \\(N\\), only the shape function derivatives of element \\(e\\) are non-zero in this block row, such that \\(G^k_e\\) is sparse. We store the gradients separately per dimension, as </p> \\[ G^k = \\begin{bmatrix} G^k_1 \\\\  \\vdots \\\\  G^k_{|E|} \\\\ \\end{bmatrix} \\in \\mathbb{R}^{|E|q \\times n} , \\] <p>and then stack them vertically into </p> \\[ G = \\begin{bmatrix} G^1 \\\\ \\vdots \\\\ G^d \\end{bmatrix} \\in \\mathbb{R}^{d|E|q \\times n} . \\] <p>The application of \\(G\\) onto \\(u\\) thus computes each spatial derivative of \\(u\\) at element quadrature points. Each \\(G^k u\\) computes the \\(k^\\text{th}\\) spatial derivative of \\(u(X)\\) at all element quadrature points, and each \\(G^k_e u\\) computes its \\(k^\\text{th}\\) spatial derivative at element \\(e\\)'s quadrature points.</p> <p>If the gradient appears in the problem (i.e. PDE or other) itself, and the problem has been closed under Galerkin projection, we must now compute the \"Galerkin\" version of the gradient, i.e. \\(\\int_{\\Omega} \\nabla u(X) \\phi_i(X) \\partial \\Omega = \\langle \\nabla u, \\phi_i \\rangle\\). By approximation and linearity of the gradient operator, such an expression becomes </p> \\[ \\int_{\\Omega} \\nabla u(X) \\phi_i(X) \\partial \\Omega = \\sum_j u_j \\int_{\\Omega} \\phi_i(X) \\nabla \\phi_j(X) \\partial \\Omega . \\] <p>If \\(\\phi_i\\) has order \\(p\\), then \\(\\phi_i \\nabla \\phi_j\\) has order \\(2p - 1\\). Thus, armed with the quadrature matrix \\(Q\\) and shape function matrix \\(N\\) of quadrature order \\(2p - 1\\), </p> \\[ \\left[ I_{d \\times d} \\otimes N^T Q \\right] G u = \\bar{G} u \\] <p>computes the gradient in the Galerkin sense, where \\(I_{d \\times d}\\) is the identity matrix and \\(\\bar{G}\\) is the Galerkin projected gradient operator. Its entries are </p> \\[ \\bar{G}^k_{ij} = \\int_{\\Omega} \\phi_i(X) \\frac{\\partial \\phi_j(X)}{\\partial X_k} \\partial \\Omega  \\] <p>for \\(k=1,2,\\dots,d\\). </p>"},{"location":"course/fem/operators/#laplacian-matrix","title":"Laplacian matrix","text":"<p>The Poisson problem discretized the Laplacian matrix into \\(A\\) where \\(A_{ij} = \\int_{\\Omega} \\phi_i(X) \\Delta \\phi_j(X) \\partial \\Omega\\). However, this results in a non-symmetric matrix, and requires shape functions of order \\(p \\geq 2\\), meaning we wouldn't be able to use linear shape functions to solve a problem involving the Laplacian of the solution. Thus, in practice, we will make use of multivariable integration by parts, i.e. Green's identities, to transform \\(\\Delta u(X)\\) into</p> \\[ \\sum_j u_j \\int_{\\Omega} \\phi_i(X) \\Delta \\phi_j(X) \\partial \\Omega = \\sum_j u_j  \\left[ \\int_{\\Omega} -\\nabla \\phi_i(X) \\cdot \\nabla \\phi_j(X) \\partial \\Omega +  \\int_{\\partial \\Omega} \\phi_i(X) \\nabla \\phi_j(X) \\cdot n \\partial S \\right] . \\] \\[ Au = Lu + Nu \\] <p>Here, \\(\\int_{\\partial \\Omega} \\partial S\\) is to be interpreted as a boundary integral (over \\(\\Omega\\)'s boundary) with \\(n\\) being the boundary's normal. The integration by parts reveals the symmetric Laplacian matrix \\(L \\in \\mathbb{R}^{n \\times n}\\), and the Neumann matrix \\(N \\in \\mathbb{R}^{n \\times n}\\). In fact, \\(L\\) is desirably both symmetric and negative semi-definite (with only rank-1 deficiency). If Neumann boundary conditions have been specified as a known function </p> \\[ g(X) = \\nabla u(X) \\cdot n  \\] <p>on the domain's boundary, i.e. \\(X \\in \\partial \\Omega\\), then we replace \\(Nu\\) by \\(g \\in \\mathbb{R}^{n \\times n}\\) such that \\(g_i = \\int_{\\partial \\Omega} g(X) \\phi_i(X) \\partial S\\). Because this integral is defined over the boundary of the FEM meshing of \\(\\Omega\\), we can similarly extract the boundary mesh for \\(\\partial \\Omega\\), preserving node indexing. We can then discretize \\(g(X)\\) on this boundary mesh using FEM once again as either a load vector if \\(g(X)\\) is defined on boundary faces, or as \\(Mg\\) using the boundary mesh's mass matrix \\(M\\) and coefficients \\(g\\) defined on boundary vertices. There are many cases where the Neumann boundary conditions are even simpler, however, i.e. when \\(g(X) = \\nabla u(X) \\cdot n = 0\\), in which case the Laplacian matrix is exactly \\(L\\). The resulting Poisson problem would then be \\(Lu=f\\), which is a symmetric negative semi-definite linear system which can be solved efficiently.</p> <p>The matrix \\(L\\) is quite famous and is equivalent to the so-called \"cotangent Laplacian\" or the \"Laplace-Beltrami\" operator mentioned in the literature, for the case of triangular meshes embedded in 3D. Instead of the general derivation presented in this document, when assuming linear shape functions, it is possible to derive quite elegant analytic expressions involving the cotangent function to compute its entries. In our Physics Based Animation Toolkit, we also like to refer to \\(L\\) as the symmetric part of the Laplacian matrix. If \\(\\phi_i(X)\\) is of polynomial order \\(p\\), then \\(L\\)'s integrands are polynomials of order \\(2(p-1)\\). A polynomial quadrature rule of order \\(2(p-1)\\) is thus sufficient for exact computation of \\(L\\).</p> <p>The element Laplacian matrices are</p> \\[ L^e =  -\\begin{bmatrix}  \\int_{\\Omega^e} \\nabla \\phi_1 \\nabla \\phi_1 \\partial \\Omega^e &amp; \\dots &amp; \\int_{\\Omega^e} \\nabla \\phi_1 \\nabla \\phi_{n^e} \\partial \\Omega^e \\\\  \\vdots &amp;  &amp; \\vdots \\\\  \\int_{\\Omega^e} \\nabla \\phi_{n^e} \\nabla \\phi_1 \\partial \\Omega^e &amp; \\dots &amp; \\int_{\\Omega^e} \\nabla \\phi_{n^e} \\nabla \\phi_{n^e} \\partial \\Omega^e  \\end{bmatrix} , \\] <p>where local indexing \\(l =1,2,\\dots,n^e\\) has been used.</p> <p>Once again, we can reuse our previously defined operators to construct the Laplacian instead. Using the matrices \\(Q\\) and \\(G\\) of appropriate quadrature order, we get that</p> \\[ L = -G^T \\left[ I_{d \\times d} \\otimes Q \\right] G \\in \\mathbb{R}^{n \\times n} . \\]"},{"location":"course/fem/operators/#divergence-matrix","title":"Divergence matrix","text":"<p>Interestingly, we can discretize the divergence operator by simply transposing the gradient matrix, i.e. \\(D = G^T \\in \\mathbb{R}^{n \\times d|E|q}\\). Given some vector field \\(F(X)\\) discretized at element quadrature points \\(X(\\xi_g)\\), where each scalar field component \\(F_k(X)\\) of \\(F(X)\\) has been discretized into \\(F_k \\in \\mathbb{R}^{|E|q \\times 1}\\) and stacked into \\(F \\in \\mathbb{R}^{d|E|q \\times 1}\\), </p> \\[ DF = G^T F \\in \\mathbb{R}^{n \\times 1} \\] <p>computes its divergence. However, in the previous construction of the Laplacian, or more precisely, the symmetric part of the Galerkin projected Laplacian, we had that </p> \\[ L = -G^T \\left[ I_{d \\times d} \\otimes Q \\right] G = \\left[ -D \\left(I_{d \\times d} \\otimes Q \\right) \\right] G , \\] <p>where the divergence operator \\(D\\) must act on the gradient \\(G\\) of an FEM function through integration. As such, when solving problems involving divergence, such as least-squares gradient matching problems, i.e. the Poisson problem</p> \\[ \\min_u ||\\nabla u - F||_2^2 \\leftrightarrow \\Delta u = \\nabla \\cdot F , \\] <p>the divergence operator should act on the target vector field \\(F(X)\\) in the integrated (i.e. Galerkin) sense. In matrix notation, we discretize the divergence of the target vector field \\(F(X)\\) as \\(-D \\left[ I_{d \\times d} \\otimes Q \\right] F\\), for discrete \\(F\\) constructed as in previous examples.</p>"},{"location":"course/fem/shape_functions/","title":"Shape Functions","text":""},{"location":"course/fem/shape_functions/#shape-functions","title":"Shape functions","text":"<p>Although our motivating example shows how, armed with basis functions \\(\\phi_i\\), continuous problems reduce to discrete ones, we have yet to explicitly define such functions. However, we did implicitly define them by stating that they must satisfy the following properties 1. \\(\\phi_i\\) is a polynomial 2. \\(\\phi_i(X_j) = \\delta_{ij}\\) 3. \\(<code>\\phi_i(X) = \\begin{cases}N_i^e(X) &amp; X \\in \\Omega^e, \\text{node} \\;i\\; \\text{and element} \\;e\\; \\text{are adjacent}\\\\ 0 &amp; \\text{otherwise}\\end{cases}</code>\\)</p> <p>The third property introduces \\(\\Omega^e\\), which refers to the domain of element \\(e\\), i.e. the space it occupies. Naturally, meshes are made of non-overlapping geometric primitives (i.e. the \"elements\" \\(\\Omega^e\\)), connected through their boundaries. This means that evaluating \\(\\phi_i(X)\\) is achieved by the following steps. 1. Find which element \\(e\\) contains the point \\(X\\).  2. Evaluate \\(N_i^e(X)\\).</p> <p>Fortunately, our shape functions have \\(C^0\\) continuity at element boundaries, meaning \\(N_i^e(X) = N_i^{e'}(X)\\) on the boundary between adjacent elements \\(e\\) and \\(e'\\) (due to uniqueness of interpolating polynomials). Hence, if a point \\(X\\) lies on the boundary between 2 or more elements, we can pick any of these elements in step 1.</p> <p>We now focus on the secret sauce, the element shape functions \\(N_i^e(X)\\). Properties 1. and 3. state that \\(\\phi_i(X)\\) is a polynomial and evaluates to \\(N_i^e(X)\\) on the element \\(e\\). Thus, \\(N_i^e(X)\\) is a polynomial on the element \\(e\\). Polynomials can be written as linear combinations of basis polynomials \\(P_k(X)\\). Suppose that \\(n^e = |\\text{nodes}(e)|\\), then if we have \\(n^e\\) such basis polynomials \\(P_k(X)\\), and we have that $N_i^e(X) = \\sum_{j \\in \\text{nodes}(e)} \\alpha_{ij} P_j(X) $. More compactly,</p> \\[ N_i^e(X) = P(X)^T \\alpha_i , \\] <p>where \\(<code>P(X) = \\begin{bmatrix} P_1(X) &amp; \\dots &amp; P_{n^e}(X) \\end{bmatrix}^T</code>\\) and \\(<code>\\alpha_i = \\begin{bmatrix} \\alpha_{i1} &amp; \\dots &amp; \\alpha_{in^e} \\end{bmatrix}^T</code>\\). Property 2, i.e. the Kronecker delta property, thus translates into \\(N_i^e(X_j) = \\delta_{ij}\\) on element \\(e\\). Substituting \\(N_i^e(X_j)\\) for its polynomial expansion in the Kronecker delta property yields</p> \\[ \\begin{bmatrix} P(X_1) &amp; \\dots &amp; P(X_{n^e}) \\end{bmatrix}^T \\begin{bmatrix} \\alpha_1 &amp; \\dots &amp; \\alpha_{n^e} \\end{bmatrix} = I_{n^e \\times n^e} , \\] <p>where \\(I_{n^e \\times n^e} \\in \\mathbb{R}^{n^e \\times n^e}\\) is the identity matrix. In matrix notation,</p> \\[ P^T \\alpha = I_{n^e \\times n^e} , \\] <p>where we have conveniently numbered the nodes of element \\(e\\) as \\(l=1,2,\\dots,n^e\\). This numbering choice is often referred to as the \"local\" indexing of the nodes of element \\(e\\). The \"global\" indexing of these same nodes refers to the actual nodal indices \\(i\\) corresponding to local nodal indices \\(l\\).</p> <p>The polynomial basis generally has a quite simple analytical form. For example, taking the monomial basis in 1D for a quadratic polynomial yields \\(P_1(X) = 1, P_2(X) = X, P_3(X) = X^2\\). A linear monomial basis in 3D yields \\(P_1(X)=1, P_2(X) = X_1, P_3(X) = X_2, P_4(X)=X_3\\). These basis polynomials are thus super easy to evaluate, differentiate or integrate in code. What we really need is to find the coefficients \\(\\alpha_{ij}\\) that will finalize our definition of the shape functions \\(N_i^e(X)\\). Fortunately, solving the Kronecker equation above amounts to computing the inverse of the transposed matrix of polynomials \\(P^T\\) </p> \\[ \\alpha = P^{-T} . \\] <p>Armed with each matrix \\(A\\) stored for its corresponding element in an FEM computer program, we can easily evaluate \\(\\phi_i(X)\\) by finding an element \\(e\\) containing point \\(X\\), converting global node index \\(i\\) into its corresponding local index \\(l\\), and returning \\(P(X)^T \\alpha_{l}\\). Fortunately, these polynomial coefficient matrices \\(A\\) are to be precomputed only once, in parallel, for each element.</p> <p>Unfortunately, \\(P^T\\) can easily become ill-conditioned, which makes its inversion numerically unstable, especially for higher-order polynomial basis'. This phenomenon depends on the geometry of the mesh elements, i.e. the positions of the nodes \\(X_i\\). Intuitively, ill-conditioning of \\(P^T\\) means that some of its cofficients are really large (in magnitude), and some of them are really small (in magnitude). Taking as an example the 1D quadratic monomial evaluated at some element's node with position \\(X=1000\\), we get that its corresponding row in \\(P^T\\) would be \\(<code>\\begin{bmatrix}1 &amp; 1000 &amp; 1000000\\end{bmatrix}</code>\\). Clearly, this is ill-conditioned. </p> <p>To address this issue, it is common in practice to define some map \\(X(\\xi)\\) that takes points in some reference space to the domain \\(\\Omega\\), and its inverse \\(\\xi(X) = X^{-1}(\\xi)\\) such that we can construct shape functions in the reference space, where the geometry of the elements will yield well-conditioned \\(P^T\\). In fact, this concept leads to defining the so-called reference elements. The maps \\(X(\\xi)\\) and \\(\\xi(X)\\) are then defined per-element, and always map from and to the reference element, respectively. Reference shape functions are subsequently defined on the reference element and constructed only once. Evaluating a basis function \\(\\phi_i(X)\\) on element \\(e\\) thus amounts to mapping \\(X\\) to \\(\\xi\\) using element \\(e\\)'s inverse map \\(\\xi(X)\\), and then evaluating the reference shape function associated with node \\(i\\) of element \\(e\\). Mathematically, assuming that \\(N_l(\\xi)\\) is the reference shape function for domain node \\(i\\) associated with reference node \\(l\\) on the reference element, we have that</p> \\[ \\phi_i(X) = N_l(\\xi(X)) . \\] <p>Chapter 9.3 of Hans Petter Langtangen's FEM book (highly recommend that book) provides the following pedagogical visuals, in which dots represent nodes of a quadratic FEM triangular element.</p> Linear map from reference element (local) to domain element (global). Non-linear map from reference element (local) to domain element (global)."},{"location":"course/fem/shape_functions/#lagrange-elements","title":"Lagrange elements","text":"<p>Perhaps the simplest and/or most popular type of reference element is the Lagrange element. This type of element is defined by a polynomial order \\(p\\) used to construct the shape functions. As described above, there must be as many polynomial basis' as nodes for the inverse of \\(P^T\\) to exist, i.e. \\(P^T\\) must be square. Lagrange elements in 3D thus define their nodes with coordinates \\(<code>\\xi_l \\in \\left\\{ \\left(\\frac{a}{p}, \\frac{b}{p}, \\frac{c}{p}\\right) \\right\\}</code>\\) and corresponding polynomial basis functions \\(<code>P_l \\in \\left\\{ \\xi_x^a \\xi_y^b \\xi_z^c \\right\\}</code>\\) for integer values \\(0 \\leq a,b,c \\leq p\\), where they are used as powers. In 2D, we only use \\(a\\) and \\(b\\). In 1D, we reduce further to simply using \\(a\\). Simplex elements, such as triangles and tetrahedra have the additional constraint \\(a+b+c \\leq p\\), wheras line segments, quadrilaterals and hexahedra do not.</p> <p>Taken once again from chapter 9.3 of Hans Petter Langtangen's FEM book, here are examples of Lagrange elements and their nodes in dimensions <code>1,2,3</code>.</p> Linear Lagrange simplex elements. Quadratic Lagrange simplex elements."},{"location":"course/fem/shape_functions/#mapping-fromto-reference","title":"Mapping from/to reference","text":"<p>Given exact reference node placements \\(\\xi_l\\) and the polynomial basis functions \\(P_l(\\xi)\\), we can obtain our reference shape functions \\(N_l(\\xi) = P(\\xi)^T \\alpha_l\\). We can recover the map \\(X(\\xi)\\) easily by simple interpolation of domain positions \\(X_i\\) of domain nodes and elements, \\(i\\) and \\(e\\), stored on corresponding reference nodes \\(l\\) with positions \\(\\xi_l\\) and shape functions \\(N_l(\\xi)\\) on the reference element. Mathematically, we write the map as</p> \\[ X(\\xi) = X^e N(\\xi) , \\] <p>where \\(<code>X^e = \\begin{bmatrix} X_1 &amp; \\dots &amp; X_{n^e} \\end{bmatrix} \\in \\mathbb{R}^{d \\times n^e}</code>\\) are element \\(e\\)'s nodes' positions \\(X_i\\), \\(<code>N(\\xi) = \\begin{bmatrix} N_1(\\xi) &amp; \\dots &amp; N_{n^e}(\\xi) \\end{bmatrix}^T \\in \\mathbb{R}^{n^e}</code>\\) are the reference shape functions evaluated at \\(\\xi\\), and \\(d\\) is the number of embedding dimensions for \\(X_i\\). </p> <p>The inverse map \\(\\xi(X)\\) is, however, not so trivial in the general case. One way to obtain \\(\\xi(X)\\) numerically is by solving the non-linear least-squares problem</p> \\[ \\min_{\\xi} || X - X(\\xi) ||_2^2 , \\] <p>for which we can use a Gauss-Newton algorithm. If the map \\(X(\\xi)\\) is linear, however, its jacobian \\(J\\) must be constant. We can choose an arbitrary point around which to perform a Taylor expansion of \\(X(\\xi)\\), for example, the reference space's origin \\(\\xi_1 = 0\\), which we know is mapped to \\(X_1\\) in Lagrange elements, revealing </p> \\[ X(\\xi) = X_1 + J \\xi . \\] <p>If the reference element's dimensions match the domain's embedding dimensions, \\(J\\) is square and</p> \\[ \\xi(X) = J^{-1} (X - X_1) . \\] <p>Otherwise, the normal equations may be used to define it instead</p> \\[ \\xi(X) = (J^T J)^{-1} J^T (X - X_1) . \\]"},{"location":"course/fem/shape_functions/#derivatives","title":"Derivatives","text":"<p>Computing derivatives of basis functions \\(\\phi_i(X)\\) also amounts to computing derivatives of shape functions \\(N_i^e(X)\\). Because our shape functions are now defined in reference space, we must use the chain rule of differentiation to compute \\(\\nabla_X N_i^e(X) = \\nabla_X N_l(\\xi(X))\\), such that </p> \\[ \\nabla_X \\phi_i(X) = \\nabla_X N_i^e(X) = \\nabla_\\xi N_l(\\xi(X)) \\nabla_X \\xi(X)  \\] <p>for \\(X \\in \\Omega^e\\).</p> <p>The gradient of the reference shape functions with respect to reference positions is easy enough to compute, since we just need to differentiate polynomials \\(\\xi_x^a \\xi_y^b \\xi_z^c\\). The jacobian \\(\\nabla_X \\xi(X)\\) of the inverse map is, again, not so trivial in the general case. If a Gauss-Newton algorithm is used to compute \\(\\xi(X)\\) as described above, we need to compute and accumulate gradients of the Gauss-Newton iterations by chain rule. Once again, though, if the map is linear, we can use the previous derivations of the linear inverse map to get \\(\\nabla_X \\xi(X)\\) as </p> \\[ \\nabla_X \\xi(X) = J^{-1} \\] <p>for a square jacobian \\(J\\), and </p> \\[ \\nabla_X \\xi(X) = (J^T J)^{-1} J^T \\] <p>for a non-square jacobian \\(J\\).</p>"},{"location":"course/fem/shape_functions/#summary","title":"Summary","text":"<p>Basis functions \\(\\phi_i(X)\\) are constructed piece-wise in mesh elements \\(e\\) adjacent to node \\(i\\) via element shape functions \\(N_i^e(X)\\). To evaluate \\(\\phi_i(X)\\), we find element \\(e\\) adjacent to node \\(i\\) containing point \\(X\\), and evaluate \\(N_i^e(X)\\). The shape functions are polynomials which depend on the geometry of their associated element, and we compute them by inverting a matrix \\(P^T\\) of polynomials evaluated at element \\(e\\)'s nodes. To avoid ill-conditioning of the matrix inversion problem, we instead define a reference element that is well-conditioned, and construct reference shape functions \\(N_l(\\xi)\\) there. Evaluating our basis functions in the domain then amounts to \\(\\phi_i(X) = N_i^e(X) = N_l(\\xi(X))\\), where \\(\\xi(X)\\) is the inverse map taking domain positions \\(X\\) to reference positions \\(\\xi\\), as opposed to the map \\(X(\\xi)\\) which takes reference positions to domain positions. Gradients of basis functions can be computed by carrying out the chain rule of differentiation through \\(N_l(\\xi)\\) and \\(\\xi(X)\\). The specific placement of nodes and the associated basis polynomials in reference space defines the type of an FEM element. We present the classic Lagrange element as a simple yet popular choice.</p> <p>Because functions discretized on an FEM mesh have a linear combination structure \\(u(X) \\approx \\Phi^T u\\), and \\(u\\) is a simple vector of constant (with respect to \\(X\\)) coefficients, differential operators \\(D(\\cdot)\\) applied to \\(u(X)\\) need only be applied to the basis functions \\(\\phi_i(X)\\) by linearity. In other words, \\(L(u(X)) = \\sum_i u_i L(\\phi_i(X))\\). Hence, the gradient \\(\\nabla u(X)\\), for example, amounts to \\(\\sum_i u_i \\nabla \\phi_i(X)\\), where we have shown how to evaluate \\(\\nabla \\phi_i(X)\\). The same applies to other differential operators, such as \\(\\Delta, \\nabla^2, \\nabla \\cdot, \\int \\partial\\), etc.</p>"},{"location":"course/fem/spatial_integration/","title":"Spatial Integration","text":""},{"location":"course/fem/spatial_integration/#spatial-integration","title":"Spatial integration","text":"<p>Many of the problems solved by FEM are defined by integration over the domain \\(\\Omega\\). For example, we have seen that PDEs can be solved with a Galerkin projection, which involves computing \\(\\int_{\\Omega} L(\\Phi^T u) \\phi_i(X) \\partial \\Omega\\), where \\(L(\\cdot)\\) is a PDE. Spatial integration also arises when we wish to minimize some quantity \"everywhere\" in the domain, a very common scenario. For example, suppose we have a function \\(h(X)\\) which measures temperature in the domain \\(\\Omega\\), and suppose that there is a heat source in some region \\(\\Omega_h \\subset \\Omega\\). Maybe we want to minimize the temperature everywhere in \\(\\Omega\\), in the presence of such a heat source. Mathematically, we would thus want to minimize the energy \\(\\int_{\\Omega} h(X) \\partial \\Omega\\) subject to \\(h(\\Omega_h) = h_D\\), where \\(h_D\\) is the temperature of the heat source.</p> <p>Thanks to the separability of definite integrals, integrals over the domain \\(\\Omega\\) can be broken up into a sum of integrals over element domains \\(\\Omega^e\\), since elements are non-overlapping and cover the domain. In other words, given some integrand \\(F(X)\\), </p> \\[ \\int_{\\Omega} F(X) \\partial \\Omega = \\sum_{e \\in E} \\int_{\\Omega^e} F(X) \\partial \\Omega . \\] <p>As such, if we know how to compute an element integral, then we know how to compute integrals over the whole domain by summation. However, elements can have many different configurations depending on the problem. Fortunately, we can leverage the method of integration by substitution (i.e. change of variables), our fixed reference element with known bounds, and the map \\(X(\\xi)\\) to compute domain element integrals by integrating in the reference element. Mathematically, </p> \\[ \\int_{\\Omega^e} F(X) \\partial \\Omega = \\int_{\\Omega^\\text{ref}} F(X(\\xi)) |\\det \\nabla_\\xi X| \\partial \\Omega^\\text{ref} , \\] <p>where \\(\\Omega^\\text{ref}\\) is the reference element's domain. For reference line, quadrilateral and hexahedral elements, the bounds of integration (i.e. the domain of \\(\\Omega^\\text{ref}\\)) are \\(0 \\leq \\xi \\leq 1\\). For a triangle, the bounds are \\(\\xi_x \\in [0, 1], \\xi_y \\in [0,1-\\xi_x]\\), whereas for tetrahedra, they become \\(\\xi_x \\in [0, 1], \\xi_y \\in [0, 1- \\xi_x], \\xi_z \\in [0, 1 - \\xi_y - \\xi_x]\\). If the map \\(X(\\xi)\\) is not square, i.e. the reference element is of lower dimension than the mesh's embedding dimensions, then the determinant \\(\\det \\nabla_\\xi X\\) is undefined. In fact, a more general expression would replace \\(\\det \\nabla_\\xi\\) with \\(\\Pi_{k} \\sigma_k\\) where \\(\\sigma_k\\) are singular values of \\(\\nabla_\\xi X\\). This approach must be used, for example, when using FEM on 3D triangles, where the reference triangle is inherently a 2D object. For the remainder of the text, we will stick to the notation \\(\\det \\nabla_\\xi X\\), although the singular value variant of the expression is to be implicitly understood.</p> <p>Although it is possible to analytically derive computable expressions for these reference integrals, it is often not practical to do so. A more general approach (and sometimes more efficient) approach is to use numerical integration, also known as quadrature. Quadrature rules are pairs of weights \\(w_g\\) and points \\(\\xi_g\\) for which an integral can be approximated by simple weighted sum of the integrand, without computing antiderivatives, as</p> \\[ \\int_{\\Omega^\\text{ref}} F(X(\\xi)) |\\det \\nabla_\\xi X| \\partial \\Omega^\\text{ref} \\approx \\sum_g w_g F(X(\\xi_g)) |\\det \\nabla_\\xi X| . \\] <p>Such weights \\(w_g\\) and points \\(\\xi_g\\) are often provided in the form of tables by many FEM implementations for common geometries such as the reference line, triangle, quadrilateral, tetrahedral and hexahedral elements. The specific number of pairs \\((w_g, \\xi_g)\\) and their values depends on the geometry and the type of integrand. Generally, quadrature rules for polynomial integrands are easily obtainable and are, in fact, exact up to floating point precision. The higher the order of integrand, the higher the number of required pairs \\((w_g, \\xi_g)\\) to compute the analytic integral exactly. This statement is relevant, because FEM shape functions are, in fact, polynomials, and integrals over FEM functions become integrals over FEM shape functions, thanks to linearity of the integral operator and the linear combination structure of FEM functions. As an example, consider how \\(\\int_{\\Omega} \\sum_i u_i \\phi_i(X) \\partial \\Omega = \\sum_i u_i \\int_{\\Omega} \\phi_i(X) \\partial \\Omega\\), where we need only know how to integrate \\(\\int_{\\Omega} \\phi_i(X) \\partial \\Omega\\). Many other integral expressions also reduce to integrating simple integrands involving only basis functions \\(\\phi_i(X)\\). Thus, such integrands are also polynomials, and can be computed exactly via quadrature.</p>"},{"location":"course/fem/spatial_integration/#summary","title":"Summary","text":"<p>In FEM, integrals over the domain \\(\\Omega\\) are equivalent to the sum of integrals over elements \\(\\Omega^e\\). These element integrals, in turn, can be computed in the reference element using the map \\(X(\\xi)\\) and the change of variables technique, because reference elements have fixed and known bounds. The key ingredients to implementing integrals on a computer are to first obtain tables of quadrature weights and points \\((w_g, \\xi_g)\\) for the specific element and integrand, the integrand \\(F(X)\\), the map \\(X(\\xi)\\) and the determinant of its jacobian \\(|\\det \\nabla_\\xi X|\\). In pseudocode,</p> <pre><code>def integrate_element(wg, Xig, F, X, detJ):\n    I = 0\n    for g in range(wg.shape[0]):\n        I = I + wg[g] * F(X.map(Xig[:,g])) * detJ[g]\n    return I\n\ndef integrate_domain(mesh, wg, Xig, F):\n    I = 0\n    for e in mesh.elements:\n        X = mesh.reference_to_domain_map(e)\n        detJ = X.jacobian_determinants_at_reference_points(Xig)\n        I = I + integrate_element(wg, Xig, F, X, detJ)\n    return I\n</code></pre>"},{"location":"examples/broad_phase/","title":"3D Broad Phase Collision Detection with PBAT","text":"<p>This repository contains a Python script for broad phase collision detection using the Physics Based Animation Toolkit (PBAT). It includes two algorithms for collision detection between 3D meshes: - Sweep and Prune - Bounding Volume Hierarchy (BVH)</p> <p>The GUI is built using Polyscope, a 3D visualization framework, allowing real-time interaction with the meshes.</p>"},{"location":"examples/broad_phase/#features","title":"Features","text":"<ul> <li>Supports tetrahedral meshes in <code>.vtk</code>, <code>.msh</code>, <code>.obj</code>, and other common formats.</li> <li>Animates and visualizes broad phase collision detection in 3D.</li> <li>Allows switching between collision detection algorithms.</li> <li>Includes a configurable user interface for controlling the animation, speed, and algorithm.</li> <li>Optional export of frame-by-frame screenshots.</li> </ul>"},{"location":"examples/broad_phase/#requirements","title":"Requirements","text":"<p>Before running the script, ensure the following packages are installed:</p> <ul> <li>pbatoolkit (Python bindings of PBAT)</li> <li>Polyscope (for 3D visualization)</li> <li>Meshio (for reading and writing mesh files)</li> <li>NumPy (for numerical operations)</li> <li>ImGui (Polyscope's GUI framework)</li> </ul> <p>Install dependencies via <code>pip</code>:</p> <pre><code>pip install numpy==1.26 scipy==1.14 meshio==5.3.5 libigl==v2.5.1 polyscope==2.2.1ilupp==1.0.2 ipctk==1.2.0 networkx==3.3\n</code></pre>"},{"location":"examples/broad_phase/#usage","title":"Usage","text":""},{"location":"examples/broad_phase/#command-line-arguments","title":"Command-line Arguments","text":"<p>The script accepts the following arguments:</p> <ul> <li><code>-i</code> / <code>--input</code> (required): Path to the input tetrahedral mesh file (supported formats include <code>.vtk</code>, <code>.obj</code>, <code>.msh</code>, etc.)</li> <li><code>-o</code> / <code>--output</code> (optional): Directory path where screenshots will be saved when exporting frames. Default is the current directory.</li> <li><code>-t</code> / <code>--translation</code> (optional): Vertical translation applied to the second mesh in the animation. Default is <code>0.1</code>.</li> </ul>"},{"location":"examples/broad_phase/#example-usage","title":"Example Usage","text":"<p>To run the script with an input mesh:</p> <pre><code>python broad_phase.py -i path/to/mesh.vtk\n</code></pre> <p>To specify an output directory for saving screenshots:</p> <pre><code>python broad_phase.py -i path/to/mesh.vtk -o output/directory\n</code></pre>"},{"location":"examples/broad_phase/#interacting-with-the-gui","title":"Interacting with the GUI","text":"<p>Once the script is running, the Polyscope window will open, showing the meshes and the results of collision detection. The GUI includes the following controls:</p> <ul> <li>Algorithm: Choose between <code>Sweep and Prune</code> or <code>Bounding Volume Hierarchy</code> for collision detection.</li> <li>Box expansion: Adjust the amount of expansion applied to the bounding boxes for collision detection.</li> <li>Speed: Adjust the speed of the mesh animation.</li> <li>Export: Toggle to save screenshots of the frames.</li> <li>Animate: Toggle to start or stop the animation.</li> <li>Step: Manually step through the animation frame by frame.</li> </ul>"},{"location":"examples/broad_phase/#output","title":"Output","text":"<p>The script will update the visualization in real time, displaying the active overlapping simplices (tetrahedrons) in the meshes. The overlapping regions will be highlighted, and users can switch between algorithms to compare performance.</p>"},{"location":"examples/broad_phase/#screenshot-exporting","title":"Screenshot Exporting","text":"<p>When <code>Export</code> is enabled, the script will save screenshots of each frame to the specified output directory in <code>.png</code> format. The file names will be formatted as <code>{frame_number}.png</code>.</p>"},{"location":"examples/contact_detection/","title":"3D Vertex-Triangle Contact Detection","text":"<p>This script performs vertex-triangle contact detection using GPU acceleration and visualizes the results in real-time. It uses libraries like <code>pbatoolkit</code>, <code>meshio</code>, <code>numpy</code>, <code>polyscope</code>, and <code>igl</code> to handle geometry processing, visualization, and interaction.</p>"},{"location":"examples/contact_detection/#prerequisites","title":"Prerequisites","text":"<p>Before running the script, make sure the following libraries are installed: - <code>pbatoolkit</code> - <code>meshio</code> - <code>numpy</code> - <code>polyscope</code> - <code>igl</code></p> <p>You can install them using pip: <pre><code>pip numpy==1.26 scipy==1.14 meshio==5.3.5 libigl==v2.5.1 polyscope==2.2.1 ilupp==1.0.2 ipctk==1.2.0 networkx==3.3\n</code></pre></p>"},{"location":"examples/contact_detection/#command-line-arguments","title":"Command-line Arguments","text":"<p>The script expects the following argument:</p> <ul> <li><code>--input</code>: Path to the input mesh file (required).</li> </ul> <pre><code>python script.py --input /path/to/your/meshfile\n</code></pre>"},{"location":"examples/contact_detection/#workflow-overview","title":"Workflow Overview","text":""},{"location":"examples/contact_detection/#1-loading-the-mesh","title":"1. Loading the Mesh","text":"<p>The input mesh is read using <code>meshio</code>, which extracts the points (vertices) and tetrahedral cells of the mesh. The boundary facets are calculated using <code>igl.boundary_facets</code>.</p> <pre><code>imesh = meshio.read(args.input)\nV, T = imesh.points.astype(np.float32), imesh.cells_dict[\"tetra\"].astype(np.int32)\nF = igl.boundary_facets(T)\n</code></pre>"},{"location":"examples/contact_detection/#2-duplicating-the-mesh","title":"2. Duplicating the Mesh","text":"<p>The input mesh is duplicated to simulate a multi-layered structure. Both the vertices and the cells are duplicated and updated accordingly.</p> <pre><code>V = np.vstack((V.copy(), V.copy()))\nT = np.vstack((T.copy(), T + nverts))\nF = np.vstack((F.copy(), F + nverts))\n</code></pre>"},{"location":"examples/contact_detection/#3-bvh-bounding-volume-hierarchy","title":"3. BVH (Bounding Volume Hierarchy)","text":"<p>To optimize the detection of contact between vertices and triangles, a BVH structure is built for the tetrahedra and facets using the <code>pbatoolkit</code>.</p> <pre><code>Vquery = pbat.gpu.geometry.BvhQuery(V.shape[0], 24*T.shape[0], 8*F.shape[0])\nTbvh = pbat.gpu.geometry.Bvh(T.shape[0], 0)\nFbvh = pbat.gpu.geometry.Bvh(F.shape[0], 0)\n</code></pre>"},{"location":"examples/contact_detection/#4-animation-and-visualization","title":"4. Animation and Visualization","text":"<p>The code sets up an interactive visualization using <code>polyscope</code>, where you can animate and visualize the movement of vertices and the detection of active contact points.</p>"},{"location":"examples/contact_detection/#key-variables","title":"Key Variables:","text":"<ul> <li><code>animate</code>: Whether the mesh should be animated.</li> <li><code>dhat</code>: Radius for nearest neighbor search.</li> <li><code>show_nn_pairs</code>: Whether to display the nearest neighbors.</li> </ul>"},{"location":"examples/contact_detection/#polyscope-user-interface","title":"Polyscope User Interface:","text":"<p>A user-defined callback handles the animation, interaction, and display of results. Users can control animation speed, search radius, and enable or disable the display of nearest neighbor pairs.</p> <pre><code>def callback():\n    global dhat, t, speed, animate, N, n, export, show_nn_pairs, show_all_nn_pairs\n    # (Code to handle user input and update visualization)\n</code></pre>"},{"location":"examples/contact_detection/#5-exporting-frames","title":"5. Exporting Frames","text":"<p>You can export the current frame as a screenshot if the <code>export</code> option is enabled. Screenshots are saved as <code>.png</code> files with a frame index.</p> <pre><code>if export:\n    ps.screenshot(f\"{args.output}/{t}.png\")\n</code></pre>"},{"location":"examples/contact_detection/#6-contact-detection","title":"6. Contact Detection","text":"<p>Contact detection is performed using BVH, and results are displayed by marking active vertices and triangles.</p> <pre><code>O = Vquery.detect_overlaps(P, SV, ST, Tbvh)\nN = Vquery.detect_contact_pairs(P, SV, SF, BV, BF, Fbvh, dhat)\n</code></pre>"},{"location":"examples/contact_detection/#code-sample","title":"Code Sample","text":"<pre><code>import pbatoolkit as pbat\nimport argparse\nimport meshio\nimport numpy as np\nimport polyscope as ps\nimport igl\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(prog=\"3D vertex-triangle contact detection\")\n    parser.add_argument(\"-i\", \"--input\", help=\"Path to input mesh\", required=True)\n    args = parser.parse_args()\n\n    imesh = meshio.read(args.input)\n    V, T = imesh.points.astype(np.float32), imesh.cells_dict[\"tetra\"].astype(np.int32)\n    F = igl.boundary_facets(T)\n\n    # Duplicate mesh, BVH setup\n    V = np.vstack((V.copy(), V.copy()))\n    T = np.vstack((T.copy(), T + V.shape[0] // 2))\n    F = np.vstack((F.copy(), F + V.shape[0] // 2))\n\n    profiler = pbat.profiling.Profiler()\n    ps.init()\n\n    # Initialize visualization\n    sm = ps.register_surface_mesh(\"Boundary Mesh\", V, F)\n    vm = ps.register_volume_mesh(\"Mesh\", V, T)\n\n    def callback():\n        # Update positions and visualization\n        sm.update_vertex_positions(V)\n        vm.update_vertex_positions(V)\n\n    ps.set_user_callback(callback)\n    ps.show()\n</code></pre>"},{"location":"examples/contact_detection/#running-the-script","title":"Running the Script","text":"<p>Once the script is ready, you can run it by passing the path to the mesh file as an argument:</p> <pre><code>python script.py --input /path/to/your/meshfile\n</code></pre>"},{"location":"examples/diffusion_smoothing/","title":"Diffusion Mesh Smoothing Demo","text":"<p>This script demonstrates how to perform diffusion-based mesh smoothing using the Finite Element Method (FEM). It constructs the necessary operators for a given triangle mesh and applies a heat diffusion process to smooth the mesh. The visualization is handled through Polyscope, providing real-time feedback with controls for adjusting smoothing parameters.</p>"},{"location":"examples/diffusion_smoothing/#prerequisites","title":"Prerequisites","text":"<p>Make sure you have the required libraries installed:</p> <ul> <li><code>pbatoolkit</code></li> <li><code>igl</code></li> <li><code>polyscope</code></li> <li><code>numpy</code></li> <li><code>scipy</code></li> <li><code>meshio</code></li> </ul> <p>Install them with <code>pip</code>:</p> <pre><code>pip install pbatoolkit igl polyscope numpy scipy meshio\n</code></pre>"},{"location":"examples/diffusion_smoothing/#command-line-arguments","title":"Command-line Arguments","text":"<p>The script expects the following argument:</p> <ul> <li><code>--input</code>: Path to the input triangle mesh file (required).</li> </ul>"},{"location":"examples/diffusion_smoothing/#example-usage","title":"Example usage:","text":"<pre><code>python script.py --input /path/to/triangle/mesh.obj\n</code></pre>"},{"location":"examples/diffusion_smoothing/#workflow-overview","title":"Workflow Overview","text":""},{"location":"examples/diffusion_smoothing/#1-reading-and-preparing-the-mesh","title":"1. Reading and Preparing the Mesh","text":"<p>The input mesh is loaded using <code>meshio</code>, which reads the vertices (<code>V</code>) and faces (<code>F</code>) from the file. The data is converted to suitable types for further processing.</p> <pre><code>imesh = meshio.read(args.input)\nV, F = imesh.points, imesh.cells_dict[\"triangle\"]\nV, F = V.astype(np.float64, order='c'), F.astype(np.int64, order='c')\n</code></pre>"},{"location":"examples/diffusion_smoothing/#2-finite-element-method-fem-setup","title":"2. Finite Element Method (FEM) Setup","text":"<p>The FEM framework from <code>pbatoolkit</code> is used to set up the following:</p> <ul> <li>Laplacian Operator (<code>L</code>): Used to model the heat diffusion.</li> <li>Mass Matrix (<code>M</code>): Helps in discretizing the system.</li> </ul> <p>The <code>detJeL</code> and <code>GNeL</code> are Jacobian determinants and shape function gradients, respectively, which are necessary for constructing the FEM Laplacian.</p> <pre><code>mesh = pbat.fem.Mesh(V.T, F.T, element=pbat.fem.Element.Triangle, order=1)\ndetJeL = pbat.fem.jacobian_determinants(mesh, quadrature_order=1)\nGNeL = pbat.fem.shape_function_gradients(mesh, quadrature_order=1)\nL = pbat.fem.Laplacian(mesh, detJeL, GNeL, quadrature_order=1).to_matrix()\ndetJeM = pbat.fem.jacobian_determinants(mesh, quadrature_order=2)\nM = pbat.fem.MassMatrix(mesh, detJeM, dims=1, quadrature_order=2).to_matrix()\n</code></pre>"},{"location":"examples/diffusion_smoothing/#3-diffusion-process","title":"3. Diffusion Process","text":"<p>The diffusion is modeled using a simple heat equation. A timestep (<code>dt</code>) and diffusion coefficient (<code>c</code>) are defined, and a linear system is constructed. The matrix <code>A</code> is precomputed to enable efficient updates during smoothing.</p> <pre><code>dt = 0.016\nc = 1\nA = M - c*dt*L\nAinv = pbat.math.linalg.ldlt(A)\nAinv.compute(A)\n</code></pre>"},{"location":"examples/diffusion_smoothing/#4-visualization","title":"4. Visualization","text":"<p>The script uses Polyscope to visualize the input mesh and the smoothed result. Two meshes are registered: one for the original model and one for the smoothed version. A user interface is provided to adjust the timestep (<code>dt</code>) and the diffusion coefficient (<code>c</code>), as well as toggle the smoothing process.</p> <pre><code>ps.init()\nvmm = ps.register_surface_mesh(\"model\", V, F)\nvms = ps.register_surface_mesh(\"smoothed\", V, F)\n</code></pre>"},{"location":"examples/diffusion_smoothing/#5-user-interaction","title":"5. User Interaction","text":"<p>The user can adjust the following parameters:</p> <ul> <li>Timestep (<code>dt</code>): Controls the smoothing speed.</li> <li>Diffusion Coefficient (<code>c</code>): Affects the intensity of the smoothing.</li> <li>Smooth Toggle: Enables or disables the smoothing process in real-time.</li> </ul> <pre><code>def callback():\n    global dt, Ainv, M, L, smooth, V, c\n    dtchanged, dt = imgui.InputFloat(\"dt\", dt)\n    cchanged, c = imgui.SliderFloat(\"c\", c, v_min=0, v_max=100)\n    if dtchanged or cchanged:\n        A = M - c*dt*L\n        Ainv.factorize(A)\n    _, smooth = imgui.Checkbox(\"smooth\", smooth)\n    if smooth:\n        V = Ainv.solve(M @ V)\n        vms.update_vertex_positions(V)\n</code></pre>"},{"location":"examples/diffusion_smoothing/#code-sample","title":"Code Sample","text":"<pre><code>import pbatoolkit as pbat\nimport igl\nimport polyscope as ps\nimport polyscope.imgui as imgui\nimport numpy as np\nimport meshio\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(prog=\"Diffusion mesh smoothing demo\")\n    parser.add_argument(\"-i\", \"--input\", help=\"Path to input triangle mesh\", required=True)\n    args = parser.parse_args()\n\n    imesh = meshio.read(args.input)\n    V, F = imesh.points, imesh.cells_dict[\"triangle\"]\n    V, F = V.astype(np.float64, order='c'), F.astype(np.int64, order='c')\n\n    mesh = pbat.fem.Mesh(V.T, F.T, element=pbat.fem.Element.Triangle, order=1)\n    detJeL = pbat.fem.jacobian_determinants(mesh, quadrature_order=1)\n    GNeL = pbat.fem.shape_function_gradients(mesh, quadrature_order=1)\n    L = pbat.fem.Laplacian(mesh, detJeL, GNeL, quadrature_order=1).to_matrix()\n    detJeM = pbat.fem.jacobian_determinants(mesh, quadrature_order=2)\n    M = pbat.fem.MassMatrix(mesh, detJeM, dims=1, quadrature_order=2).to_matrix()\n\n    dt = 0.016\n    c = 1\n    A = M - c*dt*L\n    Ainv = pbat.math.linalg.ldlt(A)\n    Ainv.compute(A)\n\n    ps.init()\n    vmm = ps.register_surface_mesh(\"model\", V, F)\n    vms = ps.register_surface_mesh(\"smoothed\", V, F)\n    smooth = False\n\n    def callback():\n        global dt, Ainv, M, L, smooth, V, c\n        dtchanged, dt = imgui.InputFloat(\"dt\", dt)\n        cchanged, c = imgui.SliderFloat(\"c\", c, v_min=0, v_max=100)\n        if dtchanged or cchanged:\n            A = M - c*dt*L\n            Ainv.factorize(A)\n        _, smooth = imgui.Checkbox(\"smooth\", smooth)\n        if smooth:\n            V = Ainv.solve(M @ V)\n            vms.update_vertex_positions(V)\n\n    ps.set_user_callback(callback)\n    ps.show()\n</code></pre>"},{"location":"examples/diffusion_smoothing/#running-the-script","title":"Running the Script","text":"<p>Run the script and pass the path to a triangle mesh file to apply diffusion-based smoothing:</p> <pre><code>python script.py --input /path/to/triangle/mesh.obj\n</code></pre>"},{"location":"examples/elasticity_higher_order/","title":"Simple 3D Elastic Simulation using Quadratic FEM Tetrahedra","text":"<p>This script demonstrates a 3D elastic simulation based on quadratic Finite Element Method (FEM) tetrahedra. It simulates the elastic behavior of a 3D mesh under gravity, solving for the deformation of the mesh over time using a Newton-Raphson method.</p>"},{"location":"examples/elasticity_higher_order/#prerequisites","title":"Prerequisites","text":"<p>Ensure the following libraries are installed before running the script:</p> <ul> <li><code>pbatoolkit</code></li> <li><code>meshio</code></li> <li><code>polyscope</code></li> <li><code>numpy</code></li> <li><code>scipy</code></li> </ul> <p>You can install the required packages using pip:</p> <pre><code>pip install pbatoolkit meshio polyscope numpy scipy\n</code></pre>"},{"location":"examples/elasticity_higher_order/#command-line-arguments","title":"Command-line Arguments","text":"<p>The script accepts several command-line arguments for customization:</p> <ul> <li><code>--input</code>: Path to the input tetrahedral mesh file (required).</li> <li><code>--refined-input</code>: Path to a refined surface mesh for visualization (required).</li> <li><code>--mass-density</code>: Mass density of the material (default: 1000).</li> <li><code>--young-modulus</code>: Young's modulus of the material (default: 1e6).</li> <li><code>--poisson-ratio</code>: Poisson's ratio of the material (default: 0.45).</li> </ul>"},{"location":"examples/elasticity_higher_order/#example-usage","title":"Example usage:","text":"<pre><code>python script.py --input /path/to/input_mesh.vtk --refined-input /path/to/refined_mesh.obj --mass-density 1000 --young-modulus 1e6 --poisson-ratio 0.45\n</code></pre>"},{"location":"examples/elasticity_higher_order/#workflow-overview","title":"Workflow Overview","text":""},{"location":"examples/elasticity_higher_order/#1-loading-the-meshes","title":"1. Loading the Meshes","text":"<p>Two meshes are loaded using <code>meshio</code>: - A tetrahedral domain mesh for the FEM simulation (<code>V</code>, <code>C</code>). - A refined surface mesh for visualization purposes (<code>VR</code>, <code>FR</code>).</p> <pre><code>imesh = meshio.read(args.input)\nV, C = imesh.points, imesh.cells_dict[\"tetra\"]\nrimesh = meshio.read(args.rinput)\nVR, FR = rimesh.points, rimesh.cells_dict[\"triangle\"]\n</code></pre>"},{"location":"examples/elasticity_higher_order/#2-setting-up-fem-simulation","title":"2. Setting up FEM Simulation","text":"<p>The FEM Mesh is constructed using quadratic tetrahedral elements. We calculate the mass matrix and precompute its inverse for efficient simulations. The load vector due to gravity is also constructed.</p> <pre><code>mesh = pbat.fem.Mesh(V.T, C.T, element=pbat.fem.Element.Tetrahedron, order=2)\ndetJeM = pbat.fem.jacobian_determinants(mesh, quadrature_order=4)\nM = pbat.fem.MassMatrix(mesh, detJeM, rho=args.rho, dims=3, quadrature_order=4).to_matrix()\nMinv = pbat.math.linalg.ldlt(M)\nMinv.compute(M)\n</code></pre>"},{"location":"examples/elasticity_higher_order/#3-hyperelastic-potential-and-boundary-conditions","title":"3. Hyperelastic Potential and Boundary Conditions","text":"<p>A Stable Neo-Hookean Hyperelastic Potential is used to model the elastic energy of the material, governed by the Young\u2019s modulus and Poisson\u2019s ratio. Dirichlet boundary conditions are set at the extremities of the mesh.</p> <pre><code>Y = np.full(mesh.E.shape[1], args.Y)\nnu = np.full(mesh.E.shape[1], args.nu)\npsi = pbat.fem.HyperElasticEnergy.StableNeoHookean\nhep = pbat.fem.HyperElasticPotential(mesh, detJeU, GNeU, Y, nu, energy=psi, quadrature_order=4)\nhep.precompute_hessian_sparsity()\n</code></pre>"},{"location":"examples/elasticity_higher_order/#4-solving-the-elasticity-problem","title":"4. Solving the Elasticity Problem","text":"<p>The simulation is performed using Newton\u2019s method. At each timestep, we solve the system for displacement, update the velocity and position of the nodes, and compute the forces acting on the mesh.</p> <pre><code>Hdd = hep.to_matrix()[:, dofs].tocsr()[dofs, :]\nHddinv = pbat.math.linalg.ldlt(Hdd)\nHddinv.analyze(Hdd)\n</code></pre>"},{"location":"examples/elasticity_higher_order/#5-visualization","title":"5. Visualization","text":"<p>Polyscope is used for visualizing the simulation in real time. The mesh deformation is shown dynamically as the simulation runs, and users can control the simulation speed and toggle the animation.</p> <pre><code>ps.set_up_dir(\"z_up\")\nvm = ps.register_volume_mesh(\"Domain\", V, C)\nsm = ps.register_surface_mesh(\"Visual\", VR, FR)\n</code></pre>"},{"location":"examples/elasticity_higher_order/#6-user-interaction","title":"6. User Interaction","text":"<p>The user interface provides controls to adjust the time step (<code>dt</code>) and toggle the animation. Clicking the \"step\" button advances the simulation by one step.</p> <pre><code>def callback():\n    global dt, animate, step\n    changed, dt = imgui.InputFloat(\"dt\", dt)\n    changed, animate = imgui.Checkbox(\"animate\", animate)\n    step = imgui.Button(\"step\")\n</code></pre>"},{"location":"examples/elasticity_higher_order/#code-sample","title":"Code Sample","text":"<pre><code>import pbatoolkit as pbat\nimport meshio\nimport numpy as np\nimport polyscope as ps\nimport polyscope.imgui as imgui\nimport math\nimport argparse\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(prog=\"Simple 3D elastic simulation using quadratic FEM tetrahedra\")\n    parser.add_argument(\"-i\", \"--input\", help=\"Path to input mesh\", type=str, required=True)\n    parser.add_argument(\"-r\", \"--refined-input\", help=\"Path to refined input mesh\", type=str, required=True)\n    parser.add_argument(\"-m\", \"--mass-density\", help=\"Mass density\", type=float, default=1000.)\n    parser.add_argument(\"-Y\", \"--young-modulus\", help=\"Young's modulus\", type=float, default=1e6)\n    parser.add_argument(\"-n\", \"--poisson-ratio\", help=\"Poisson's ratio\", type=float, default=0.45)\n    args = parser.parse_args()\n\n    # Load meshes\n    imesh = meshio.read(args.input)\n    V, C = imesh.points, imesh.cells_dict[\"tetra\"]\n    V, C = V.astype(np.float64, order='c'), C.astype(np.int64, order='c')\n    rimesh = meshio.read(args.rinput)\n    VR, FR = rimesh.points, rimesh.cells_dict[\"triangle\"]\n    VR, FR = VR.astype(np.float64, order='c'), FR.astype(np.int64, order='c')\n\n    # FEM setup\n    mesh = pbat.fem.Mesh(V.T, C.T, element=pbat.fem.Element.Tetrahedron, order=2)\n    detJeM = pbat.fem.jacobian_determinants(mesh, quadrature_order=4)\n    rho = args.rho\n    M = pbat.fem.MassMatrix(mesh, detJeM, rho=rho, dims=3, quadrature_order=4).to_matrix()\n    Minv = pbat.math.linalg.ldlt(M)\n    Minv.compute(M)\n\n    # Gravity load vector\n    g = np.zeros(mesh.dims)\n    g[-1] = -9.81\n    detJef = pbat.fem.jacobian_determinants(mesh, quadrature_order=2)\n    fe = np.tile(rho * g[:, np.newaxis], mesh.quadrature_weights(2).shape[0] * mesh.E.shape[1])\n    qgf = pbat.fem.inner_product_weights(mesh, quadrature_order=2).flatten(order=\"F\")\n    Qf = sp.sparse.diags_array([qgf], offsets=[0])\n    Nf = pbat.fem.shape_function_matrix(mesh, quadrature_order=2)\n    f = fe @ Qf @ Nf\n    f = f.reshape(math.prod(f.shape), order=\"F\")\n\n    # Hyperelastic potential\n    Y = np.full(mesh.E.shape[1], args.Y)\n    nu = np.full(mesh.E.shape[1], args.nu)\n    psi = pbat.fem.HyperElasticEnergy.StableNeoHookean\n    hep = pbat.fem.HyperElasticPotential(mesh, detJeU, GNeU, Y, nu, energy=psi, quadrature_order=4)\n    hep.precompute_hessian_sparsity()\n\n    # Visualization setup\n    ps.init()\n    vm = ps.register_volume_mesh(\"Domain\", V, C)\n    sm = ps.register_surface_mesh(\"Visual\", VR, FR)\n    ps.show()\n</code></pre>"},{"location":"examples/elasticity_higher_order/#running-the-script","title":"Running the Script","text":"<pre><code>python script.py --input /path/to/input_mesh.vtk --refined-input /path/to/refined_mesh.obj\n</code></pre>"},{"location":"examples/notebooks/vbd/","title":"Set up some example parameters (replace with your own mesh inputs if necessary)","text":"In\u00a0[\u00a0]: Copied! <pre># Install necessary packages if not already installed (uncomment if needed)\n!pip install numpy==1.26 scipy==1.14 meshio==5.3.5 libigl==v2.5.1 polyscope==2.2.1 ilupp==1.0.2 ipctk==1.2.0 networkx==3.3\n</pre> # Install necessary packages if not already installed (uncomment if needed) !pip install numpy==1.26 scipy==1.14 meshio==5.3.5 libigl==v2.5.1 polyscope==2.2.1 ilupp==1.0.2 ipctk==1.2.0 networkx==3.3 <pre>Collecting numpy==1.26\n  Downloading numpy-1.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\nCollecting scipy==1.14\n  Downloading scipy-1.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\nCollecting meshio==5.3.5\n  Downloading meshio-5.3.5-py3-none-any.whl.metadata (11 kB)\nCollecting libigl==v2.5.1\n  Downloading libigl-2.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\nCollecting polyscope==2.2.1\n  Downloading polyscope-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\nCollecting ilupp==1.0.2\n  Downloading ilupp-1.0.2.tar.gz (155 kB)\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n  Installing backend dependencies ... done\n  Preparing metadata (pyproject.toml) ... done\nCollecting ipctk==1.2.0\n  Downloading ipctk-1.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\nCollecting networkx==3.3\n  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\nCollecting rich (from meshio==5.3.5)\n  Downloading rich-13.9.2-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from rich-&gt;meshio==5.3.5) (2.2.0)\nRequirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich-&gt;meshio==5.3.5) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from markdown-it-py&gt;=2.2.0-&gt;rich-&gt;meshio==5.3.5) (0.1.2)\nDownloading numpy-1.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.9 MB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 17.9/17.9 MB 49.7 MB/s eta 0:00:00:00:01\nDownloading scipy-1.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.8 MB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 40.8/40.8 MB 71.7 MB/s eta 0:00:00:00:0100:01\nDownloading meshio-5.3.5-py3-none-any.whl (166 kB)\nDownloading libigl-2.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 16.2/16.2 MB 41.6 MB/s eta 0:00:0000:01\nDownloading polyscope-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.8/3.8 MB 27.6 MB/s eta 0:00:00\nDownloading ipctk-1.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.7/1.7 MB 28.4 MB/s eta 0:00:00\nDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.7/1.7 MB 29.6 MB/s eta 0:00:00\nDownloading rich-13.9.2-py3-none-any.whl (242 kB)\nBuilding wheels for collected packages: ilupp\n  Building wheel for ilupp (pyproject.toml) ... \\</pre> In\u00a0[\u00a0]: Copied! <pre>import meshio\nimport numpy as np\nimport scipy as sp\nimport igl\nimport polyscope as ps\nimport polyscope.imgui as imgui\nimport math\nimport networkx as nx\nimport itertools\nimport pbatoolkit as pbat\n</pre> import meshio import numpy as np import scipy as sp import igl import polyscope as ps import polyscope.imgui as imgui import math import networkx as nx import itertools import pbatoolkit as pbat In\u00a0[\u00a0]: Copied! <pre>def combine(V: list, C: list):\n    Vsizes = [Vi.shape[0] for Vi in V]\n    Csizes = [Ci.shape[0] for Ci in C]\n    Voffsets = list(itertools.accumulate(Vsizes))\n    Coffsets = list(itertools.accumulate(Csizes))\n    C = [C[i] + Voffsets[i] - Vsizes[i] for i in range(len(C))]\n    C = np.vstack(C)\n    V = np.vstack(V)\n    return V, Vsizes, C, Coffsets, Csizes\n\ndef boundary_triangles(C: np.ndarray, Coffsets: list, Csizes: list):\n    F = [None]*len(Csizes)\n    for i in range(len(F)):\n        begin = Coffsets[i] - Csizes[i]\n        end = begin + Csizes[i]\n        F[i] = igl.boundary_facets(C[begin:end, :])\n        F[i][:, :2] = np.roll(F[i][:, :2], shift=1, axis=1)\n    Fsizes = [Fi.shape[0] for Fi in F]\n    F = np.vstack(F)\n    return F, Fsizes\n\ndef vertex_tetrahedron_adjacency_graph(V, C):\n    row = np.repeat(range(C.shape[0]), C.shape[1])\n    col = C.flatten()\n    data = np.zeros_like(C)\n    for i in range(C.shape[1]):\n        data[:, i] = i\n    data = data.flatten()\n    GVT = sp.sparse.coo_array((data, (row, col)), shape=(\n        C.shape[0], V.shape[0])).asformat(\"csc\")\n    return GVT\n\ndef color_dict_to_array(Cdict, n):\n    C = np.zeros(n)\n    keys = [key for key in Cdict.keys()]\n    values = [value for value in Cdict.values()]\n    C[keys] = values\n    return C\n\ndef partition_vertices(GVT, dbcs):\n    GVV = GVT.T @ GVT\n    Gprimal = nx.Graph(GVV)\n    GC = nx.greedy_color(Gprimal, strategy=\"random_sequential\")\n    GC = color_dict_to_array(GC, GVT.shape[1]).astype(np.int32)\n    npartitions = GC.max() + 1\n    partitions = []\n    for p in range(npartitions):\n        vertices = np.nonzero(GC == p)[0]\n        vertices = np.setdiff1d(vertices, dbcs).tolist()\n        if len(vertices) &gt; 0:\n            partitions.append(vertices)\n    return partitions, GC\n</pre> def combine(V: list, C: list):     Vsizes = [Vi.shape[0] for Vi in V]     Csizes = [Ci.shape[0] for Ci in C]     Voffsets = list(itertools.accumulate(Vsizes))     Coffsets = list(itertools.accumulate(Csizes))     C = [C[i] + Voffsets[i] - Vsizes[i] for i in range(len(C))]     C = np.vstack(C)     V = np.vstack(V)     return V, Vsizes, C, Coffsets, Csizes  def boundary_triangles(C: np.ndarray, Coffsets: list, Csizes: list):     F = [None]*len(Csizes)     for i in range(len(F)):         begin = Coffsets[i] - Csizes[i]         end = begin + Csizes[i]         F[i] = igl.boundary_facets(C[begin:end, :])         F[i][:, :2] = np.roll(F[i][:, :2], shift=1, axis=1)     Fsizes = [Fi.shape[0] for Fi in F]     F = np.vstack(F)     return F, Fsizes  def vertex_tetrahedron_adjacency_graph(V, C):     row = np.repeat(range(C.shape[0]), C.shape[1])     col = C.flatten()     data = np.zeros_like(C)     for i in range(C.shape[1]):         data[:, i] = i     data = data.flatten()     GVT = sp.sparse.coo_array((data, (row, col)), shape=(         C.shape[0], V.shape[0])).asformat(\"csc\")     return GVT  def color_dict_to_array(Cdict, n):     C = np.zeros(n)     keys = [key for key in Cdict.keys()]     values = [value for value in Cdict.values()]     C[keys] = values     return C  def partition_vertices(GVT, dbcs):     GVV = GVT.T @ GVT     Gprimal = nx.Graph(GVV)     GC = nx.greedy_color(Gprimal, strategy=\"random_sequential\")     GC = color_dict_to_array(GC, GVT.shape[1]).astype(np.int32)     npartitions = GC.max() + 1     partitions = []     for p in range(npartitions):         vertices = np.nonzero(GC == p)[0]         vertices = np.setdiff1d(vertices, dbcs).tolist()         if len(vertices) &gt; 0:             partitions.append(vertices)     return partitions, GC In\u00a0[\u00a0]: Copied! <pre>input_mesh_paths = ['mesh1.obj', 'mesh2.obj']  # Example mesh files (replace with actual paths)\noutput_path = \".\"  # Example output path\nrho = 1000.\nY = 1e6\nnu = 0.45\ntranslation = 0.1\npercent_fixed = 0.01\nfixed_axis = 2\nfixed_end = \"min\"\n</pre> input_mesh_paths = ['mesh1.obj', 'mesh2.obj']  # Example mesh files (replace with actual paths) output_path = \".\"  # Example output path rho = 1000. Y = 1e6 nu = 0.45 translation = 0.1 percent_fixed = 0.01 fixed_axis = 2 fixed_end = \"min\" In\u00a0[\u00a0]: Copied! <pre>imeshes = [meshio.read(input) for input in input_mesh_paths]\nV, C = [imesh.points / (imesh.points.max() - imesh.points.min()) for imesh in imeshes], [\n    imesh.cells_dict[\"tetra\"] for imesh in imeshes]\nfor i in range(len(V) - 1):\n    extent = V[i][:, -1].max() - V[i][:, -1].min()\n    offset = V[i][:, -1].max() - V[i+1][:, -1].min()\n    V[i+1][:, -1] += offset + extent*translation\n</pre> imeshes = [meshio.read(input) for input in input_mesh_paths] V, C = [imesh.points / (imesh.points.max() - imesh.points.min()) for imesh in imeshes], [     imesh.cells_dict[\"tetra\"] for imesh in imeshes] for i in range(len(V) - 1):     extent = V[i][:, -1].max() - V[i][:, -1].min()     offset = V[i][:, -1].max() - V[i+1][:, -1].min()     V[i+1][:, -1] += offset + extent*translation In\u00a0[\u00a0]: Copied! <pre>detJeM = pbat.fem.jacobian_determinants(mesh, quadrature_order=2)\nM = pbat.fem.MassMatrix(mesh, detJeM, rho=rho,\n                        dims=1, quadrature_order=2).to_matrix()\nm = np.array(M.sum(axis=0)).squeeze()\n</pre> detJeM = pbat.fem.jacobian_determinants(mesh, quadrature_order=2) M = pbat.fem.MassMatrix(mesh, detJeM, rho=rho,                         dims=1, quadrature_order=2).to_matrix() m = np.array(M.sum(axis=0)).squeeze() In\u00a0[\u00a0]: Copied! <pre>detJeU = pbat.fem.jacobian_determinants(mesh, quadrature_order=1)\nGNeU = pbat.fem.shape_function_gradients(mesh, quadrature_order=1)\nqgf = pbat.fem.inner_product_weights(mesh, quadrature_order=1).flatten(order=\"F\")\nQf = sp.sparse.diags_array([qgf], offsets=[0])\nNf = pbat.fem.shape_function_matrix(mesh, quadrature_order=1)\ng = np.zeros(mesh.dims)\ng[-1] = -9.81\nfe = np.tile(rho*g[:, np.newaxis], mesh.E.shape[1])\nf = fe @ Qf @ Nf\na = f / m\n</pre> detJeU = pbat.fem.jacobian_determinants(mesh, quadrature_order=1) GNeU = pbat.fem.shape_function_gradients(mesh, quadrature_order=1) qgf = pbat.fem.inner_product_weights(mesh, quadrature_order=1).flatten(order=\"F\") Qf = sp.sparse.diags_array([qgf], offsets=[0]) Nf = pbat.fem.shape_function_matrix(mesh, quadrature_order=1) g = np.zeros(mesh.dims) g[-1] = -9.81 fe = np.tile(rho*g[:, np.newaxis], mesh.E.shape[1]) f = fe @ Qf @ Nf a = f / m In\u00a0[\u00a0]: Copied! <pre>Y = np.full(mesh.E.shape[1], Y)\nnu = np.full(mesh.E.shape[1], nu)\nmue = Y / (2*(1+nu))\nlambdae = (Y*nu) / ((1+nu)*(1-2*nu))\n</pre> Y = np.full(mesh.E.shape[1], Y) nu = np.full(mesh.E.shape[1], nu) mue = Y / (2*(1+nu)) lambdae = (Y*nu) / ((1+nu)*(1-2*nu)) In\u00a0[\u00a0]: Copied! <pre>Xmin = mesh.X.min(axis=1)\nXmax = mesh.X.max(axis=1)\nextent = Xmax - Xmin\nif fixed_end == \"min\":\n    Xmax[fixed_axis] = Xmin[fixed_axis] + percent_fixed*extent[fixed_axis]\nelif fixed_end == \"max\":\n    Xmin[fixed_axis] = Xmax[fixed_axis] - percent_fixed*extent[fixed_axis]\naabb = pbat.geometry.aabb(np.vstack((Xmin, Xmax)).T)\nvdbc = aabb.contained(mesh.X)\na[:, vdbc] = 0.\n</pre> Xmin = mesh.X.min(axis=1) Xmax = mesh.X.max(axis=1) extent = Xmax - Xmin if fixed_end == \"min\":     Xmax[fixed_axis] = Xmin[fixed_axis] + percent_fixed*extent[fixed_axis] elif fixed_end == \"max\":     Xmin[fixed_axis] = Xmax[fixed_axis] - percent_fixed*extent[fixed_axis] aabb = pbat.geometry.aabb(np.vstack((Xmin, Xmax)).T) vdbc = aabb.contained(mesh.X) a[:, vdbc] = 0. In\u00a0[\u00a0]: Copied! <pre>Vcollision = np.unique(F)\nVC = Vcollision[:, np.newaxis].T\nvbd = pbat.gpu.vbd.Vbd(V.T, VC, F.T, C.T)\nvbd.a = a\nvbd.m = m\nvbd.wg = detJeU / 6\nvbd.GNe = GNeU\nvbd.lame = np.vstack((mue, lambdae))\nGVT = vertex_tetrahedron_adjacency_graph(V, C)\nvbd.GVT = GVT.indptr, GVT.indices, GVT.data\n</pre> Vcollision = np.unique(F) VC = Vcollision[:, np.newaxis].T vbd = pbat.gpu.vbd.Vbd(V.T, VC, F.T, C.T) vbd.a = a vbd.m = m vbd.wg = detJeU / 6 vbd.GNe = GNeU vbd.lame = np.vstack((mue, lambdae)) GVT = vertex_tetrahedron_adjacency_graph(V, C) vbd.GVT = GVT.indptr, GVT.indices, GVT.data In\u00a0[\u00a0]: Copied! <pre>GVTtopology = GVT.copy()\nGVTtopology.data[:] = 1\npartitions, GC = partition_vertices(GVTtopology, vdbc)\nvbd.partitions = partitions\nthread_block_size = 64\nvbd.set_gpu_block_size(thread_block_size)\n</pre> GVTtopology = GVT.copy() GVTtopology.data[:] = 1 partitions, GC = partition_vertices(GVTtopology, vdbc) vbd.partitions = partitions thread_block_size = 64 vbd.set_gpu_block_size(thread_block_size) In\u00a0[\u00a0]: Copied! <pre>ps.set_verbosity(0)\nps.set_up_dir(\"z_up\")\nps.set_front_dir(\"neg_y_front\")\nps.set_ground_plane_mode(\"shadow_only\")\nps.set_ground_plane_height_factor(0.5)\nps.set_program_name(\"Vertex Block Descent\")\nps.init()\nvm = ps.register_volume_mesh(\"Simulation mesh\", V, C)\nvm.add_scalar_quantity(\"Coloring\", GC, defined_on=\"vertices\", cmap=\"jet\")\npc = ps.register_point_cloud(\"Dirichlet\", V[vdbc, :])\n</pre> ps.set_verbosity(0) ps.set_up_dir(\"z_up\") ps.set_front_dir(\"neg_y_front\") ps.set_ground_plane_mode(\"shadow_only\") ps.set_ground_plane_height_factor(0.5) ps.set_program_name(\"Vertex Block Descent\") ps.init() vm = ps.register_volume_mesh(\"Simulation mesh\", V, C) vm.add_scalar_quantity(\"Coloring\", GC, defined_on=\"vertices\", cmap=\"jet\") pc = ps.register_point_cloud(\"Dirichlet\", V[vdbc, :]) In\u00a0[\u00a0]: Copied! <pre>def callback():\n    global dt, iterations, substeps, rho_chebyshev, thread_block_size, initialization_strategy, RdetH, kD\n    global animate, export, t\n    global profiler\n\n    changed, dt = imgui.InputFloat(\"dt\", dt)\n    changed, iterations = imgui.InputInt(\"Iterations\", iterations)\n    changed, substeps = imgui.InputInt(\"Substeps\", substeps)\n    changed, rho_chebyshev = imgui.InputFloat(\n        \"Chebyshev rho\", rho_chebyshev)\n    changed, kD = imgui.InputFloat(\n        \"Damping\", kD, format=\"%.8f\")\n    changed, RdetH = imgui.InputFloat(\n        \"Residual det(H)\", RdetH, format=\"%.15f\")\n    changed, thread_block_size = imgui.InputInt(\n        \"Thread block size\", thread_block_size)\n    changed = imgui.BeginCombo(\n        \"Initialization strategy\", str(initialization_strategy).split('.')[-1])\n    if changed:\n        for i in range(len(initialization_strategies)):\n            _, selected = imgui.Selectable(\n                str(initialization_strategies[i]).split('.')[-1], initialization_strategy == initialization_strategies[i])\n            if selected:\n                initialization_strategy = initialization_strategies[i]\n        imgui.EndCombo()\n    vbd.initialization_strategy = initialization_strategy\n    vbd.kD = kD\n    vbd.RdetH = RdetH\n    changed, animate = imgui.Checkbox(\"Animate\", animate)\n    changed, export = imgui.Checkbox(\"Export\", export)\n    step = imgui.Button(\"Step\")\n    reset = imgui.Button(\"Reset\")\n\n    if reset:\n        vbd.x = mesh.X\n        vbd.v = np.zeros(mesh.X.shape)\n        vm.update_vertex_positions(mesh.X.T)\n        t = 0\n\n    vbd.set_gpu_block_size(thread_block_size)\n\n    if animate or step:\n        profiler.begin_frame(\"Physics\")\n        vbd.step(dt, iterations, substeps, rho_chebyshev)\n        profiler.end_frame(\"Physics\")\n\n        V = vbd.x.T\n        if export:\n            ps.screenshot(f\"{output_path}/{t}.png\")\n\n        vm.update_vertex_positions(V)\n        t = t+1\n\n    imgui.Text(f\"Frame={t}\")\n</pre> def callback():     global dt, iterations, substeps, rho_chebyshev, thread_block_size, initialization_strategy, RdetH, kD     global animate, export, t     global profiler      changed, dt = imgui.InputFloat(\"dt\", dt)     changed, iterations = imgui.InputInt(\"Iterations\", iterations)     changed, substeps = imgui.InputInt(\"Substeps\", substeps)     changed, rho_chebyshev = imgui.InputFloat(         \"Chebyshev rho\", rho_chebyshev)     changed, kD = imgui.InputFloat(         \"Damping\", kD, format=\"%.8f\")     changed, RdetH = imgui.InputFloat(         \"Residual det(H)\", RdetH, format=\"%.15f\")     changed, thread_block_size = imgui.InputInt(         \"Thread block size\", thread_block_size)     changed = imgui.BeginCombo(         \"Initialization strategy\", str(initialization_strategy).split('.')[-1])     if changed:         for i in range(len(initialization_strategies)):             _, selected = imgui.Selectable(                 str(initialization_strategies[i]).split('.')[-1], initialization_strategy == initialization_strategies[i])             if selected:                 initialization_strategy = initialization_strategies[i]         imgui.EndCombo()     vbd.initialization_strategy = initialization_strategy     vbd.kD = kD     vbd.RdetH = RdetH     changed, animate = imgui.Checkbox(\"Animate\", animate)     changed, export = imgui.Checkbox(\"Export\", export)     step = imgui.Button(\"Step\")     reset = imgui.Button(\"Reset\")      if reset:         vbd.x = mesh.X         vbd.v = np.zeros(mesh.X.shape)         vm.update_vertex_positions(mesh.X.T)         t = 0      vbd.set_gpu_block_size(thread_block_size)      if animate or step:         profiler.begin_frame(\"Physics\")         vbd.step(dt, iterations, substeps, rho_chebyshev)         profiler.end_frame(\"Physics\")          V = vbd.x.T         if export:             ps.screenshot(f\"{output_path}/{t}.png\")          vm.update_vertex_positions(V)         t = t+1      imgui.Text(f\"Frame={t}\") In\u00a0[\u00a0]: Copied! <pre>ps.set_user_callback(callback)\nps.show()\n</pre> ps.set_user_callback(callback) ps.show() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/notebooks/vbd/#set-up-some-example-parameters-replace-with-your-own-mesh-inputs-if-necessary","title":"Set up some example parameters (replace with your own mesh inputs if necessary)\u00b6","text":""},{"location":"examples/notebooks/vbd/#combine-the-mesh-data","title":"Combine the mesh data\u00b6","text":""},{"location":"examples/notebooks/vbd/#compute-mass-matrix-and-other-physical-quantities","title":"Compute mass matrix and other physical quantities\u00b6","text":""},{"location":"examples/notebooks/vbd/#set-up-gravity-field-and-load-vector","title":"Set up gravity field and load vector\u00b6","text":""},{"location":"examples/notebooks/vbd/#material-constants","title":"Material constants\u00b6","text":""},{"location":"examples/notebooks/vbd/#boundary-conditions","title":"Boundary conditions\u00b6","text":""},{"location":"examples/notebooks/vbd/#vertex-block-descent-setup","title":"Vertex Block Descent Setup\u00b6","text":""},{"location":"examples/notebooks/vbd/#partitions-and-coloring","title":"Partitions and coloring\u00b6","text":""},{"location":"examples/notebooks/vbd/#polyscope-setup","title":"Polyscope Setup\u00b6","text":""},{"location":"examples/notebooks/vbd/#visualization-callback-function","title":"Visualization callback function\u00b6","text":""},{"location":"examples/notebooks/vbd/#set-up-polyscope-callback","title":"Set up polyscope callback\u00b6","text":""},{"location":"python/FEM/","title":"<code>pbatoolkit._pbat.fem</code> Module Documentation","text":"<p>The FEM (Finite Element Method) module in <code>pbatoolkit</code> provides a collection of functions for dealing with mesh elements, computing shape functions, jacobian determinants, and handling various FEM operators like mass matrices, stiffness matrices, and gradients.</p>"},{"location":"python/FEM/#functions","title":"Functions","text":""},{"location":"python/FEM/#1-shape_functions_at","title":"1. <code>shape_functions_at</code>","text":"<p><pre><code>shape_functions_at(mesh: pbatoolkit._pbat.fem.Mesh, Xi: numpy.ndarray) -&gt; numpy.ndarray\n</code></pre> This function computes the shape functions at specified reference points <code>Xi</code>.</p> <ul> <li>Parameters:</li> <li><code>mesh</code>: The input FEM mesh of type <code>pbatoolkit._pbat.fem.Mesh</code>.</li> <li> <p><code>Xi</code>: A 2D NumPy array of shape <code>(m, n)</code>, representing reference points.</p> </li> <li> <p>Returns: A NumPy array of shape <code>(m, n)</code> that holds the shape functions evaluated at the reference points <code>Xi</code>.</p> </li> </ul>"},{"location":"python/FEM/#2-inner_product_weights","title":"2. <code>inner_product_weights</code>","text":"<p><pre><code>inner_product_weights(mesh: pbatoolkit._pbat.fem.Mesh, quadrature_order: int = 1) -&gt; numpy.ndarray\ninner_product_weights(mesh: pbatoolkit._pbat.fem.Mesh, detJe: numpy.ndarray, quadrature_order: int = 1) -&gt; numpy.ndarray\n</code></pre> Computes the inner product weights as a product of quadrature weights and the Jacobian determinants at element quadrature points.</p> <ul> <li>Overloaded versions:</li> <li>Version 1: Takes the <code>mesh</code> and <code>quadrature_order</code>.</li> <li> <p>Version 2: Takes the <code>mesh</code>, the precomputed Jacobian determinants (<code>detJe</code>), and <code>quadrature_order</code>.</p> </li> <li> <p>Parameters:</p> </li> <li><code>mesh</code>: The input FEM mesh.</li> <li><code>detJe</code> (optional): A NumPy array of Jacobian determinants.</li> <li> <p><code>quadrature_order</code>: The order of quadrature to use (default is 1).</p> </li> <li> <p>Returns: A NumPy array of shape <code>(m, n)</code> containing the inner product weights.</p> </li> </ul>"},{"location":"python/FEM/#3-jacobian_determinants","title":"3. <code>jacobian_determinants</code>","text":"<p><pre><code>jacobian_determinants(mesh: pbatoolkit._pbat.fem.Mesh, quadrature_order: int = 1) -&gt; numpy.ndarray\n</code></pre> Computes the Jacobian determinants for each element at quadrature points.</p> <ul> <li>Parameters:</li> <li><code>mesh</code>: The input FEM mesh.</li> <li> <p><code>quadrature_order</code>: The order of quadrature for which Jacobian determinants are computed.</p> </li> <li> <p>Returns: A NumPy array containing the Jacobian determinants at each quadrature point.</p> </li> </ul>"},{"location":"python/FEM/#4-reference_positions","title":"4. <code>reference_positions</code>","text":"<p><pre><code>reference_positions(mesh: pbatoolkit._pbat.fem.Mesh, E: numpy.ndarray, X: numpy.ndarray, max_iters: int = 5, eps: float = 1e-10) -&gt; numpy.ndarray\n</code></pre> Computes the reference positions for domain points <code>X</code> within elements <code>E</code>.</p> <ul> <li>Parameters:</li> <li><code>mesh</code>: The input FEM mesh.</li> <li><code>E</code>: A NumPy array of element indices.</li> <li><code>X</code>: A NumPy array of domain points.</li> <li><code>max_iters</code>: The maximum number of iterations for the computation (default: 5).</li> <li> <p><code>eps</code>: The tolerance level for convergence (default: <code>1e-10</code>).</p> </li> <li> <p>Returns: A NumPy array of reference positions associated with the domain points <code>X</code>.</p> </li> </ul>"},{"location":"python/FEM/#5-shape_function_gradients","title":"5. <code>shape_function_gradients</code>","text":"<p><pre><code>shape_function_gradients(mesh: pbatoolkit._pbat.fem.Mesh, quadrature_order: int = 1) -&gt; numpy.ndarray\n</code></pre> Computes the shape function gradients for each element at quadrature points.</p> <ul> <li>Parameters:</li> <li><code>mesh</code>: The input FEM mesh.</li> <li> <p><code>quadrature_order</code>: The quadrature order for computing the gradients (default: 1).</p> </li> <li> <p>Returns: A NumPy array representing the gradients of shape functions at the quadrature points.</p> </li> </ul>"},{"location":"python/FEM/#6-shape_function_gradients_at","title":"6. <code>shape_function_gradients_at</code>","text":"<p><pre><code>shape_function_gradients_at(mesh: pbatoolkit._pbat.fem.Mesh, E: numpy.ndarray, Xi: numpy.ndarray) -&gt; numpy.ndarray\n</code></pre> Computes the nodal shape function gradients at specified reference points <code>Xi</code>.</p> <ul> <li>Parameters:</li> <li><code>mesh</code>: The input FEM mesh.</li> <li><code>E</code>: A NumPy array of element indices.</li> <li> <p><code>Xi</code>: A NumPy array of reference points.</p> </li> <li> <p>Returns: A NumPy array of nodal shape function gradients at the reference points <code>Xi</code>.</p> </li> </ul>"},{"location":"python/FEM/#7-shape_function_matrix","title":"7. <code>shape_function_matrix</code>","text":"<p><pre><code>shape_function_matrix(mesh: pbatoolkit._pbat.fem.Mesh, quadrature_order: int = 1) -&gt; scipy.sparse.csr_matrix\n</code></pre> Constructs the shape function matrix for the FEM mesh.</p> <ul> <li>Parameters:</li> <li><code>mesh</code>: The input FEM mesh.</li> <li> <p><code>quadrature_order</code>: The quadrature order for the shape function matrix (default: 1).</p> </li> <li> <p>Returns: A sparse matrix (CSR format) representing the shape functions.</p> </li> </ul>"},{"location":"python/FEM/#data-types","title":"Data Types","text":""},{"location":"python/FEM/#elements","title":"Elements","text":"<p>Several element types are predefined in the module to be used with the mesh construction:</p> <ul> <li><code>Line</code>: Represents line elements (1D).</li> <li><code>Triangle</code>: Represents triangular elements (2D).</li> <li><code>Quadrilateral</code>: Represents quadrilateral elements (2D).</li> <li><code>Tetrahedron</code>: Represents tetrahedral elements (3D).</li> <li><code>Hexahedron</code>: Represents hexahedral elements (3D).</li> </ul>"},{"location":"python/FEM/#hyperelastic-energy-types","title":"Hyperelastic Energy Types","text":"<p>The module also provides common hyperelastic energy models:</p> <ul> <li><code>SaintVenantKirchhoff</code>: Saint Venant-Kirchhoff hyperelastic model.</li> <li><code>StableNeoHookean</code>: Stable Neo-Hookean hyperelastic model.</li> </ul>"},{"location":"python/FEM/#usage-example","title":"Usage Example","text":"<p>Below is a brief example showing how to use some functions from this module:</p> <pre><code>import pbatoolkit as pbat\nimport numpy as np\n\n# Create a mesh object (example)\nV = np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\nC = np.array([[0, 1, 2, 3]])\nmesh = pbat.fem.Mesh(V.T, C.T, element=pbat.fem.Element.Tetrahedron, order=1)\n\n# Compute the shape functions at reference points\nXi = np.array([[0.25, 0.25, 0.25]])\nshape_funcs = pbat.fem.shape_functions_at(mesh, Xi)\n\n# Compute Jacobian determinants for the mesh\njacobian_dets = pbat.fem.jacobian_determinants(mesh, quadrature_order=2)\n\n# Compute the inner product weights\nweights = pbat.fem.inner_product_weights(mesh, quadrature_order=2)\n\nprint(\"Shape Functions:\", shape_funcs)\nprint(\"Jacobian Determinants:\", jacobian_dets)\nprint(\"Inner Product Weights:\", weights)\n</code></pre>"},{"location":"python/python/","title":"Python","text":""},{"location":"python/python/#python","title":"Python","text":"<p>For a local installation, which builds from source, our Python bindings build relies on Scikit-build-core, which relies on CMake's <code>install</code> mechanism. As such, you can configure the installation as you typically would when using the CMake CLI directly, by now passing the corresponding CMake arguments in <code>pip</code>'s <code>config-settings</code> parameter (refer to the Scikit-build-core documentation for the relevant parameters). See our pyinstall workflow for working examples of building from source on Linux, MacOS and Windows. Then, assuming that external dependencies are found via CMake's <code>find_package</code>, you can build and install our Python package <code>pbatoolkit</code> locally and get the most up to date features.</p> <p>Consider using a Python virtual environment for this step.</p> <p>As an example, assuming use of <code>vcpkg</code> for external dependency management with <code>VCPKG_ROOT=path/to/vcpkg</code> set as an environment variable, run</p> <pre><code>pip install . --config-settings=cmake.args=\"--preset=pip-cuda\" -v\n</code></pre> <p>on the command line to build <code>pbatoolkit</code> from source with GPU algorithms included. Additional environment variables (i.e. <code>CUDA_PATH</code>) and/or CMake variables (i.e. <code>CMAKE_CUDA_COMPILER</code>) may be required to be set in order for CMake to correctly discover and compile against your targeted local CUDA installation. Refer to the CMake documentation for more details.</p>"},{"location":"python/python/#cuda","title":"CUDA","text":""},{"location":"python/python/#pypi","title":"PyPI","text":"<p><code>pbatoolkit-gpu</code> (downloaded from PyPI) requires dynamically linking to an instance of the - CUDA 12 Runtime library, and your - CUDA Driver.</p> <p>Recall that the CUDA Runtime is ABI compatible up to major version.</p> <p>On 64-bit Windows, these are <code>cudart64_12.dll</code> and <code>nvcuda.dll</code>. Ensure that they are discoverable via Windows' DLL search order. We recommend adding <code>&lt;drive&gt;:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.&lt;minor&gt;\\bin</code> (i.e. the binary folder of your CUDA Toolkit installation) to the <code>PATH</code> environment variable. The driver should already be on the search path by default after installation.</p> <p>On Linux, they are <code>libcudart.so.12</code> and <code>libcuda.so.1</code>. Ensure that they are discoverable via Linux's dynamic linker/loader. If they are not already in a default search path, we recommend simply updating the library search path, i.e. <code>export LD_LIBRARY_PATH=\"path/to/driver/folder;path/to/runtime/folder;$LD_LIBRARY_PATH\"</code>.</p> <p>MacOS does not support CUDA GPUs.</p> <p>Our <code>pbatoolkit-gpu</code> prebuilt binaries include PTX, such that program load times will be delayed by JIT compilation on first use. Verify that your NVIDIA GPU supports compute capability at least 7.0. For example, only RTX 2060 up to 4090 chips are supported in the GeForce series. Runtime GPU performance may be constrained by the targeted compute capability.</p>"},{"location":"workshops/","title":"Workshops","text":"<p>We compile a set of tutorials/workshops on various topics related to physics based animation (PBA), which serve the following purposes: - Act as a persistent, accessible and hands-on learning resource for anyone interested in PBA and related topics. - Document use cases and usage patterns of our Physics Based Animation Toolkit (PBAT). - Ease the development of baseline algorithms upon which one could build on for research.</p> <ol> <li>pbatoolkit.fem</li> <li>Heat diffusion</li> <li>Harmonic solutions</li> <li>Least squares and Poisson problems</li> <li>Lagrange elements</li> </ol> <p>The reader will find that much of the content in different categories may overlap. This is unsurprising/inevitable, but hopefully, the content's categorization is not too confusing. Additional topics may also be added in the future (think fluid simulation, differentiable physics, shells, etc.) and reshuffling of the categories will be possible. There is no particular prescribed order in which to consult these tutorials, but some content may have prerequisites that will hopefully be explicitly stated.</p>"},{"location":"workshops/W1/","title":"Workshop 1: pbatoolkit's FEM module","text":"In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <pre># Import modules of interest\nimport pbatoolkit as pbat\nimport inspect\n# Consult FEM module's API\ninspect.getmembers(pbat.fem)\nhelp(pbat.fem)\nhelp(pbat.fem.Mesh)\n</pre> # Import modules of interest import pbatoolkit as pbat import inspect # Consult FEM module's API inspect.getmembers(pbat.fem) help(pbat.fem) help(pbat.fem.Mesh) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"workshops/W1/#workshop-1-pbatoolkits-fem-module","title":"Workshop 1: pbatoolkit's FEM module\u00b6","text":"<p>This first workshop on FEM aims to help the reader:</p> <ul> <li>explore/analyze FEM quantities/operators</li> <li>familiarize themself with our Physics Based Animation Toolkit's Python interface</li> </ul> <p>Start by installing the required dependencies by running <code>pip install -r requirements.txt</code> on the command line. FEM relies on having meshed geometries at hand, hence we recommend finding clean surface mesh geometry and then using our mesh processing scripts to tetrahedralize them, if you don't already have access to meshes. You can download surface meshes on Thingi10K, TurboSquid or other.</p> <p>If you are interested in profiling calls to FEM operations, also download the Tracy profiling server, run <code>tracy.exe</code> and connect to this process.</p>"},{"location":"workshops/W1/#loading-input-mesh-geometry","title":"Loading input mesh geometry\u00b6","text":"<p>Use meshio to load meshes from disk to memory, and render them using polyscope.</p>"},{"location":"workshops/W1/#constructing-fem-meshes","title":"Constructing FEM meshes\u00b6","text":"<p>From the input mesh geometry, construct an FEM mesh (i.e. <code>pbatoolkit.fem.Mesh</code>) using <code>pbatoolkit</code>. Start by exploring the API of the FEM module of <code>pbatoolkit</code>. Then, try constructing meshes of different shape function orders on either of line, triangle, and/or tetrahedral meshes. You can do the same for regular geometry (rectangles and boxes) if you want.</p> <p><code>pbatoolkit</code> expects input matrix data in column major storage (i.e. <code>order='F'</code> in numpy) and uses double precision floating point numbers as scalars, and 64-bit signed integers as indices. Vertex positions are generally packed in matrix columns, and similarly for cell indices. This format is generally compatible with other packages' APIs, using a no-copy transpose operation (i.e. a row-major <code>order='C'</code> matrix with vertex positions in rows has the same memory layout as a column-major <code>order='F'</code> matrix with vertex positions in columns).</p> <p>Use Python's <code>help</code> command on <code>pbatoolkit</code>'s mesh instance, and check that you can access its nodes' positions, its elements' nodal indices, its dimensionality, element type, etc.</p> <p>Note that the FEM mesh and the geometric mesh do NOT share the same element indices. Both the FEM and geometric mesh have the same number of elements, and they are ordered in exactly the same way, but the geometric mesh's array of vertex positions does not necessarily correspond to the FEM mesh's array of node positions.</p> <p>Keep an eye on how the number of FEM nodes changes when the mesh's shape function order changes, and the computational cost of constructing higher order meshes. Visualize the FEM mesh's nodes on top of the geometric mesh using <code>polyscope</code>.</p>"},{"location":"workshops/W1/#mass-matrix","title":"Mass matrix\u00b6","text":"<ol> <li>Construct the mass matrix using <code>pbatoolkit</code>'s built-in <code>MassMatrix</code> class, and then using only the shape function and quadrature matrices, and compare the resulting mass matrices. Call <code>to_matrix</code> to get a <code>scipy</code> sparse matrix from <code>pbatoolkit</code>'s mass matrix instance.</li> <li>Analyze its properties. Is it square, symmetric, positive definite? What is its sparsity?</li> <li>What happens if you use the correct quadrature order, a lower quadrature order, and a higher quadrature order?</li> <li>How computationally costly is mass matrix construction in both cases?</li> </ol>"},{"location":"workshops/W1/#load-vector","title":"Load vector\u00b6","text":"<ol> <li>Construct a piecewise polynomial load vector using <code>pbatoolkit</code>'s shape function and quadrature matrices (use <code>pbat.fem.shape_function_matrix</code> and <code>pbat.fem.inner_product_weights</code>). Refer to examples for help. Alternatively, the load vector can be defined at nodes, in which case you only need the mass matrix (<code>pbat.fem.MassMatrix</code>). You can use some common forcing function, like gravity, i.e. $f_e(X) = [0, 0, -9.81]$. Compare the resulting discrete load vectors.</li> <li>Try constructing different load vectors using different quadrature orders and analyze the results.</li> <li>How computationally costly is its construction in all cases?</li> </ol>"},{"location":"workshops/W1/#laplacian-matrix","title":"Laplacian matrix\u00b6","text":"<ol> <li>Construct the Laplacian matrix using <code>pbatoolkit</code>'s built-in <code>pbat.fem.Laplacian</code> class, and then using only the gradient (<code>pbat.fem.Gradient</code>) and quadrature matrices (<code>pbat.fem.inner_product_weights</code>), and compare the resulting Laplacians.</li> <li>Analyze its properties, similar to the mass matrix case.</li> <li>Try varying the quadrature orders and evaluate the consequences.</li> <li>What is the computational cost of its different construction approaches?</li> </ol>"},{"location":"workshops/W1/#higher-order-fem","title":"Higher order FEM\u00b6","text":"<p>When using higher-order FEM, it is often useful to visualize our discretized functions on refined versions of our input geometric mesh. This is due to the fact that renderers that support scalar field visualization use linear interpolation to fill the colors between mesh vertices, so we need to use \"visual\" meshes of higher resolution than our \"geometric\" mesh to see any difference.</p> <p>You can refine meshes using our mesh processing scripts. Then, in code, use <code>pbat.geometry.bvh</code> to compute a spatial query acceleration data structure, our bounding volume implementation (BVH), on the \"geometric\" mesh. Vertices of the \"visual\" mesh should be mapped to the \"computational\" mesh (i.e. the FEM mesh) by</p> <ol> <li>Querying in which element of the \"geometric\" mesh they reside. This query can be greatly accelerated using the BVH.</li> <li>Use <code>pbat.fem.reference_positions</code> to compute the reference element positions of the visual mesh nodes.</li> <li>Use <code>pbat.fem.shape_functions_at</code> to evaluate the shape functions at the visual mesh nodes, using their corresponding reference positions.</li> <li>Evaluate the FEM function by coefficient-wise multiplication between nodal coefficients and associate shape functions evaluated at visual mesh nodes, and compute their sum separately (for each visual mesh node).</li> </ol> <p>Refer to this higher order example for help.</p>"},{"location":"workshops/W1/#solutions","title":"Solutions\u00b6","text":"<p>Scripts in the examples folder show different ways to construct relevant FEM quantities using <code>pbatoolkit</code> for different mesh types, different shape function orders, and different construction approaches.</p>"},{"location":"workshops/W2/","title":"Workshop 2: Heat equation","text":"<p>The final result should be a matrix system of equations in the form $\\alpha L u = M \\frac{\\partial u}{\\partial t}$.</p> <p>The final result should be $(M - \\Delta t \\alpha  L) u^{t+1} = M u^t$.</p> In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <p>One way is to impose Dirichlet boundary conditions, i.e. constrain the solution to satisfy $u(X_D,t) = d(X_D,t)$ for some known function $d(X,t)$, where $X_D$ are positions that are part of the heat source.</p> <ol> <li>On our discrete heat equation, pick vertices that are part of the heat source, and set their corresponding entries in the solution coefficient vector $u$ to your preferred heat source's temperature. You can use <code>pbatoolkit.geometry.aabb</code> to pick all vertices inside the prescribed axis-aligned box, to facilitate vertex selection.</li> <li>Impose these Dirichlet boundary conditions as described in the documentation's section on boundary conditions. Once the known degrees of freedom are collected (in a list or array), you can use numpy.setdiff1d to get the unknowns. Using the index lists, you can extract submatrices of the lead sparse matrix via slicing with scipy.</li> </ol> In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied!"},{"location":"workshops/W2/#workshop-2-heat-equation","title":"Workshop 2: Heat equation\u00b6","text":"<p>We now turn to solving a classical (linear) partial differential equation (PDE), the heat equation</p> <p>$$ \\alpha \\Delta u(X,t) = \\frac{\\partial u(X,t)}{\\partial t} , $$</p> <p>using FEM. The solution's time integration will be discretized with a first order backward differentiation approach, otherwise known as Backward Euler.</p>"},{"location":"workshops/W2/#fem-discretization","title":"FEM discretization\u00b6","text":"<p>Start by discretizing (by hand) the heat equation in the space variables only, using FEM. Treat the time derivative of heat as a forcing function for now.</p>"},{"location":"workshops/W2/#time-discretization","title":"Time discretization\u00b6","text":"<p>Discretize the heat's time derivative, which we previously considered to be a forcing function, using backward finite differences and a time step $\\Delta t$. Collect the unknowns on the left-hand side of the discretized matrix equation.</p>"},{"location":"workshops/W2/#solve-heat-equation","title":"Solve heat equation\u00b6","text":"<ol> <li>Use <code>pbatoolkit</code>'s <code>pbatoolkit.math.linalg.ldlt</code> function to factorize the discretized heat equation's lead matrix for a given mesh of your choosing.</li> <li>Our discrete heat equation is now an initial value problem IVP, such that the initial condition $u(t=0) = u^0$ must be given. Notice that $u^t$ must be discretized at FEM nodes, since it is to be projected (in the Galerkin sense) via the mass matrix $M$. Thus, pick a subset of FEM nodes, and initialize their heat values to $1$ (or something else). Set the initial heat values of other nodes to $0$ (or something else). You can use the function <code>pbatoolkit.geometry.aabb</code> to aid in selecting FEM nodes in box regions, or select them manually in <code>polyscope</code>, Blender, MeshLab or other. Otherwise, pick at random.</li> <li>Solve the IVP for a certain number of time steps $T$ and visualize each time step's heat distribution over the mesh using <code>polyscope</code>.</li> <li>What happens when you change the diffusivity constant $\\alpha$, the time step size $\\Delta t$?</li> </ol>"},{"location":"workshops/W2/#linear-solver","title":"Linear solver\u00b6","text":"<ol> <li>Choose a different linear solver for the IVP. Try, for instance, <code>scipy</code>'s sparse LU factorization. Analyze the computational cost of different approaches.</li> <li>If the results are different, consider why.</li> <li>What happens if a dense linear solver is used, rather than a sparse one?</li> </ol>"},{"location":"workshops/W2/#heat-sources","title":"Heat sources\u00b6","text":"<p>How should you model a heat source? These are regions in your domain (i.e. the FEM mesh) which emit constant heat.</p>"},{"location":"workshops/W2/#smoothing","title":"Smoothing\u00b6","text":"<p>The physical interpretation of \"heat\" that we associated with the solution vector $u$ was not necessary. Can you apply the heat/diffusion equation to some other functions?</p> <ol> <li>Solve the heat equation on each spatial position of the FEM mesh's node positions. The initial conditions for this problem should be the initial FEM mesh's node positions. You can treat this as 3 separate IVPs for each spatial dimension. Visualize the mesh using the new positions at each time step.</li> <li>Can the discrete heat equation's lead matrix be re-used?</li> <li>Change parameters $\\alpha, \\Delta t$ and visualize results.</li> <li>Constrain some nodal positions to be fixed. What happens?</li> </ol>"},{"location":"workshops/W3/","title":"Workshop 3: Harmonic solutions","text":"<p>For the Dirichlet energy, the final result should be $\\min_u -\\frac{1}{2} u^T L u$, where $L$ is the symmetric part of the Laplacian energy. For the Laplace equation, we simply get $Lu = 0$.</p> In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <p>A better smoothness energy is described in Natural Boundary Conditions for Smoothing in Geometry Processing and A Smoothness Energy without Boundary Distortion for Curved Surfaces, among other potential approaches.</p>"},{"location":"workshops/W3/#workshop-3-harmonic-solutions","title":"Workshop 3: Harmonic solutions\u00b6","text":"<p>Workshop 2 showed that the heat/diffusion equation could be used on general functions (i.e. heat or positions) to smooth them. As the solution evolved in time, it would get smoother and smoother. In fact, one might wonder what happens at the \"end\" of such a diffusion, i.e. the steady state? In this setting, the time derivative of the function would vanish, i.e. $\\frac{\\partial u}{\\partial t} = 0$, since $u$ does not change in the steady state. This leads to the harmonic (or Laplace) equation $\\Delta u = 0$. Functions which satisfy this equation are said to be harmonic. In general, harmonic functions are quite smooth, and we can thus often \"enforce\" smoothness on desired solutions by making them harmonic. This smoothness is even more obvious when we consider how harmonic functions are minimizers of the Dirichlet (or smoothness) energy</p> <p>$$ \\Delta u(X) = 0 \\longrightarrow u = \\min_u \\frac{1}{2} \\int_{\\Omega} || \\nabla u(X) ||_2^2 \\partial \\Omega . $$</p>"},{"location":"workshops/W3/#fem-discretization","title":"FEM discretization\u00b6","text":"<ol> <li>Discretize the Dirichlet energy using FEM.</li> <li>Discretize the Laplace equation using FEM.</li> </ol>"},{"location":"workshops/W3/#solving-the-laplace-equation","title":"Solving the Laplace equation\u00b6","text":"<p>In workshop 1, we learned that the Laplace equation is in fact rank deficient (by 1). We will thus need to impose some Dirichlet boundary conditions on the solution to obtain a unique harmonic function.</p> <ol> <li>Show that the Laplacian is rank deficient (on paper).</li> <li>Confirm that it is numerically rank deficient (even if workshop 1 already asks this).</li> </ol>"},{"location":"workshops/W3/#interpolation-problems","title":"Interpolation problems\u00b6","text":"<p>The \"smoothness\" minimization framework for thinking about the Laplace equation naturally allows us to formulate interpolation as finding the smoothest scalar function which interpolates the Dirichlet boundary conditions. In other words,</p> <p>$$ \\min_u -u^T L u \\quad\\text{s.t.}\\quad u_D = d_D  $$</p> <p>for some set of Dirichlet nodes $D$ and their corresponding imposed values $d_D$. Knowing that $-L$ is positive semi-definite with a single missing rank, we need at least $1$ boundary condition, and we can solve this minimization by setting the gradient to $0$, yielding the reduced linear system</p> <p>$$ L_{uu} u_u = L_{uD} d_D , $$</p> <p>where the subscripts $u,D$ are to be taken as indices to unknown degrees of freedom, and indices to known degrees of freedom (i.e. Dirichlet boundary conditions), respectively.</p> <ol> <li>Constrain 2 parts of the mesh to have values $0$ in the first part, and $1$ in the second part. Solve this Dirichlet constrained minimization. We are essentially interpolating between $0$ and $1$ on some complex and curved geometry (the mesh). Much cooler than interpolation on a line segment or in a box!</li> <li>Consider the vector-valued function of displacements from FEM nodal positions as a minimizer to the Dirichlet energy. In other words, we wish to find some smooth displacement field that takes FEM node positions to some smoother positional configuration. Constrain some region of the FEM mesh to be fixed. Constrain another region of the FEM mesh to \"move\" someplace else, by setting the corresponding Dirichlet conditions in $X,Y,Z$ dimensions to have a non-trivial displacement $[d_X, d_Y, d_Z]$. Solve for the $3$ resulting interpolants and visualize the result. You have essentially implemented harmonic deformation, a popular framework for shape deformation!</li> </ol>"},{"location":"workshops/W3/#k-harmonic-interpolation","title":"k-Harmonic interpolation\u00b6","text":"<p>It should be natural to wonder if smoother functions can be obtained in this same framework. In other words, why not minimize change in first derivatives and second derivatives and higher order derivatives? This leads to the k-harmonic equation</p> <p>$$ \\Delta^k u(X) = 0 , $$</p> <p>where $\\Delta^k$ applies the Laplacian $k$ times. Unfortunately, on first impression, it might seem like this would require our discretized $u(X)$ to be $2k$ times differentiable (ignoring that constant functions are differentiable). In other words, our basis functions $\\phi_i(X)$ should be $2k$ times differentiable. However, this problem can be solved using only linear basis functions by thinking recursively. We can create auxiliary variables $u^{k-1}(X) = \\Delta^{k-1} u(X)$ and start by solving for $\\Delta u^{k-1}(X) = 0$. Then, recursively solve $\\Delta u^{k-i}(X) = u^{k-i+1}(X)$. Unrolling this loop yields</p> <p>$$ \\Delta (\\dots (\\Delta u(X))) = 0 , $$</p> <p>where $u(X) = u^{1}(X)$. Discretizing each intermediate (sub)problem using FEM, we get that</p> <p>$$ L u^{k-i} = M u^{k-i+1} , $$</p> <p>as we have shown here, where $u^{k-i+1}(X)$ is considered as a forcing function in the $i^\\text{th}$ subproblem. Because we know that FEM functions are interpolating, this must mean that the coefficients in $u^{k-i+1}$ are the actual values of the Laplacian of $u^{k-i}(X)$ at the FEM nodes, and we can obtain such Laplacians via</p> <p>$$ M^{-1} L u^{k-i} = u^{k-i+1} . $$</p> <p>Thinking recursively again, we realize that $u^{k-i+1}$ was also obtained by applying the matrix $M^{-1} L$ to $u^{k-i+2}$. At the end of this recursion, we get $L u^k = 0$ without any mass matrix term. Unrolling this whole recursion, we end up with the system</p> <p>$$ \\left[ L M^{-1} \\dots L M^{-1} L \\dots M^{-1} L \\right] u = 0 , $$</p> <p>subject to Dirichlet boundary conditions for a well-defined solution to exist. This system is valid for linear shape functions, even if its solution is of higher order. A more in depth mixed finite elements derivation of this technique, including various other types of boundary conditions is described in Mixed Finite Elements for Variational Surface Modeling.</p> <ol> <li>What are the properties of the lead matrix $\\left[ L M^{-1} \\dots L M^{-1} L \\dots M^{-1} L \\right]$ for $k=1,2,3$?</li> <li>Solve the same interpolation problems as in the previous cell, but now minimizing a k-harmonic energy for $k=1,2,3$. What happens as $k$ increases?</li> <li>What \"energy\" are we minimizing by solving the $k$-harmonic equation? Try to derive this on paper.</li> </ol>"},{"location":"workshops/W4/","title":"Workshop 4: Poisson and least-squares problems","text":"In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied!"},{"location":"workshops/W4/#workshop-4-poisson-and-least-squares-problems","title":"Workshop 4: Poisson and least-squares problems\u00b6","text":"<p>We now turn our attention to least-squares problems on the gradient of the solution</p> <p>$$ \\min_u \\frac{1}{2} \\int_{\\Omega } || \\nabla u(X) - F(X) ||_2^2 \\partial \\Omega , $$</p> <p>and on the solution itself (function approximation by error minimization)</p> <p>$$ \\min_u \\frac{1}{2} \\int_{\\Omega } \\left[ u(X) - f(X) \\right]^2 \\partial \\Omega . $$</p>"},{"location":"workshops/W4/#poisson-equation","title":"Poisson equation\u00b6","text":"<ol> <li>Show that global minimizers to the gradient error minimization are solutions to the Poisson equation</li> </ol> <p>$$ \\Delta u(X) = \\nabla \\cdot F(X), \\quad X \\in \\Omega . $$</p> <ol> <li>Discretize the Poisson equation using FEM (on paper). If $F(X)$ is discretized at element quadrature points into $F \\in \\mathbb{R}^{d|E|q \\times 1}$, you should get $L u = -D [I_{d \\times d} \\otimes Q] F$. If $F(X)$ is discretized at the nodes into $F \\in \\mathbb{R}^{dn \\times 1}$, you should get $L u = -D [I_{d \\times d} \\otimes Q N] F$.</li> </ol>"},{"location":"workshops/W4/#heat-method-for-geodesic-distance-computation","title":"Heat method for geodesic distance computation\u00b6","text":"<p>One (of many) situations in which the Poisson equation shows up is in the Heat method for geodesic distance computation. In a nutshell, geodesic distances are lengths of the shortest paths between 2 points, where all possible paths must remain inside the domain $\\Omega$. In Euclidean space, the shortest path between 2 points is the straight line connecting the points. But let's say you live in a world that is shaped like a donut? Then traveling from one side of the donut to the other, while staying inside the donut, will require you to walk in a circular (curved) trajectory.</p> <p>There exist algorithms which compute exact geodesic distances in meshed domains. See The Discrete Geodesic Problem, Fast Exact and Approximate Geodesic Paths on Meshes, for example, for the particular case of surface meshes. In contrast, the heat method aims to compute approximate geodesic distances, but the results can be refined (see On Variational and PDE-based Distance Function Approximations, for example).</p> <p>The general idea behind the heat method is to consider how heat should flow from a source to any other point in the domain $\\Omega$ in the most optimal (shortest path) way. Consider a room (i.e. the domain $\\Omega$) that is split in half by a wall, but the wall has a hole in its center. Suppose that heat cannot pierce through the walls. Suppose that a heat source is fixed and activated on one side of the wall, and you are on the other side of the wall at the same level. How would heat flow to the other side of the room and reach you? Intuitively, it would go exactly along the wall on the same side as the source, and as soon as it encounters the hole in the wall, it will bend, go through the hole, and bend once more in the same direction, and go along the other side of the wall until it reaches you. If we normalize this heat flow, so that the heat can only ever flow with the same velocity of $1$ meter per second, then we should have essentially reconstructed the gradient of the geodesic distance function, since distance functions must have unit gradient. This leads to the following algorithm, which you will implement (on a mesh of your choosing):</p> <ol> <li><p>Compute a heat flow by first solving the heat equation subject to the initial conditions $u(X,t=0) = 1$ if $X$ is part of the heat source, and 0 otherwise. Solve for this heat for a certain period of time, obtaining $u(X,t)$, the heat at time $t$ (1 time step should be enough). The suggested time step to use (refer to the paper) is a multiple $k$ of the mesh's squared average edge length. Then, compute the negative gradient of the heat, obtaining the heat's flow $-\\nabla u(X,t)$.</p> </li> <li><p>Normalize the flow, obtaining $F(X) = \\frac{-\\nabla u(X,t)}{|\\nabla u(X,t)|}$.</p> </li> <li><p>Solve for a function $\\phi(X)$ whose gradient matches the normalized heat flow, i.e. solve the problem</p> <p>$$  \\min_\\phi \\int_{\\Omega} || \\nabla \\phi(X) - F(X) ||^2 \\partial \\Omega .  $$</p> <p>This is a Poisson problem on which FEM can be applied (as shown in the previous section). However, recall that the Laplacian $L$ is rank-deficient (but symmetric negative definite). One can use <code>pbatoolkit.math.linalg.ldlt</code> to factorize such a matrix and solve the discrete Poisson equation. However, because the laplacian $\\Delta u(X)$ is scale and translation invariant, i.e. $\\Delta u(X) = 0$, $\\Delta \\alpha u(X) = 0$, $\\Delta (u(X) + K) = 0$, the Poisson solution may be shifted and/or reflected. Knowing that the distance from the source to the source should be $0$, we can simply shift the whole Poisson solution up by the computed distance at the source (after having handled reflection). If there are many sources, use the average of the computed distances at the sources as the shift.</p> </li> <li><p>Visualize the heat distribution and the corresponding geodesic distance function on the mesh using <code>polyscope</code>. You can also visualize isolines of the distance function using <code>libigl</code>.</p> </li> <li><p>What happens if you add regularization to the Laplacian $L$ in the Poisson solve?</p> </li> </ol>"},{"location":"workshops/W4/#least-squares-error-minimization","title":"Least-squares error minimization\u00b6","text":"<p>An intuitive approach to function approximation is to directly minimize the error between our discrete FEM function $u(X)$ and some target known function $f(X)$ that we wish to approximate. This is mathematically formulated as</p> <p>$$ \\min_u \\frac{1}{2} \\int_{\\Omega} \\left[ u(X) - f(X) \\right]^2 \\partial \\Omega . $$</p> <p>If we discretize $u(X)$ using FEM into the coefficient vector $u$ and basis functions $\\phi_i(X)$, and we sample the function $f(X)$ at element quadrature points, the resulting minimization becomes</p> <p>$$ \\min_u \\frac{1}{2} (N u - f)^T Q (N u - f) . $$</p> <p>We can immediately solve this minimization by setting the gradient with respect to our unknown coefficients $u$ to zero. This leads to the linear system of equations</p> <p>$$ N^T Q N u = N^T Q f \\leftrightarrow M u = N^T Q f , $$</p> <p>where $M$ is the mass matrix, and $N^T Q$ is a Galerkin projection operator on the forcing function $f$. This hints at the fact that the forcing function $f$ may also be discretized at the FEM nodes instead, yielding</p> <p>$$ Mu = Mf \\longrightarrow u = f $$</p> <p>which immediately reveals the solution vector $u$ without requiring a linear solver. In this case, we simply need to know how to evaluate the function $f(X)$ at the nodes.</p>"},{"location":"workshops/W4/#signed-distance-function-approximation","title":"Signed distance function approximation\u00b6","text":"<p>Although signed distance functions (SDFs) in general are of great interest in many fields, we restrict our attention to approximate signed distance functions, a popular implicit representation of geometry for efficient contact detection and handling in animation. See An hp-adaptive discretization algorithm for signed distance field generation, Local Optimization for Robust Signed Distance Field Collision, Signed distance fields for polygon soup meshes, for example.</p> <p>We will use the framework of FEM function approximation presented in the previous section to approximate SDFs.</p> <ol> <li>Construct an FEM (volumetric) mesh of the domain in which you want the SDF to be supported. Use an order 1 mesh in this step. If you want to use a grid-like domain, i.e. using hexahedral FEM elements, make sure that the input hexahedral mesh geometry is given with element vertices ordered according to Lagrange coordinates. This means that the 8 hexahedron vertices should be ordered as <code>[left-front-bottom, right-front-bottom, left-back-bottom, right-back-bottom, left-front-top, right-front-top, left-back-top, right-back-top]</code>.</li> <li>Load some surface mesh of your choice. We are going to approximate the signed distance function to that surface.</li> <li>Evaluate the mesh signed distance function to the surface mesh at FEM nodes using <code>libigl</code>. Use the winding number variant for robust and accurate distance computation (if your input surface is of poor quality).</li> <li>Refine the volumetric input mesh of the domain and evaluate the FEM discretized approximate SDF at the refined volumetric mesh's vertices. Visualize the SDF on the refined mesh using <code>polyscope</code>.</li> <li>Recompute the same SDF FEM approximation pipeline, but now using quadratic shape functions, and then cubic shape functions. Visualize the results on the refined mesh again. Is there a difference?</li> <li>Evaluate the error for all 3 approximations.</li> </ol>"},{"location":"workshops/W4/#other-applications","title":"Other applications\u00b6","text":"<p>Poisson solutions are used in many other works. For example, we can reconstruct an implicit surface from a point cloud using Poisson Surface Reconstruction and its numerous derivative works, or enforce incompressibility in fluid simulation for advection-projection schemes (see Fluid Simulation for Computer Animation), for example.</p>"},{"location":"workshops/W5/","title":"Workshop 5: Lagrange elements","text":"In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied!"},{"location":"workshops/W5/#workshop-5-lagrange-elements","title":"Workshop 5: Lagrange elements\u00b6","text":"<p>We now turn to deriving shape functions for different elements, the fundamental building block for FEM discretization. In particular, we focus on the Lagrange elements. Instead of deriving shape functions by hand, we will systematically solve for these shape functions using the interpolation problem described here in the subsection on shape functions. To do so, we will use a symbolic calculator, sympy.</p>"},{"location":"workshops/W5/#lagrange-nodes","title":"Lagrange nodes\u00b6","text":"<ol> <li>Compute the Lagrange nodal positions for the reference line, triangle, quadrilateral, tetrahedron and hexahedron. You can use sympy's rational numbers to store exact coordinates.</li> <li>Visualize the reference elements and their nodes.</li> </ol>"},{"location":"workshops/W5/#lagrange-shape-functions","title":"Lagrange shape functions\u00b6","text":"<ol> <li>Setup the shape function interpolation problem, i.e. the polynomial matrix inversion problem, using symbolic positions. Use sympy's <code>Symbol</code> and similar <code>MatrixSymbol</code> classes to help out. Refer to the Introduction to SymPy and the Matrices module.</li> <li>Solve the interpolation problem (i.e. matrix inversion) using a symbolic matrix inversion.</li> <li>Compute the resulting shape functions and (pretty) print them.</li> <li>Validate that the shape functions are indeed interpolating at their associated node, and vanish at other nodes. In other words, check that they satisfy the Kronecker delta property.</li> <li>Differentiate the shape functions to obtain their gradients. Print them.</li> <li>Apply other differential operators (higher order derivatives, integrals, etc.) to the shape functions, if you are interested.</li> </ol>"},{"location":"workshops/W5/#code-generation","title":"Code generation\u00b6","text":"<ol> <li>Generate code for shape function computation using SymPy's code printers.</li> <li>Generate code for shape function gradients.</li> </ol>"},{"location":"workshops/W5/#solutions","title":"Solutions\u00b6","text":"<p>Our implementation of shape functions and their gradients is code-generated. See our Lagrange element script and the C++ code printer it uses.</p>"}]}